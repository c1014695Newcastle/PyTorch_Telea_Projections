{
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4nVUBjMT-Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "epoQhzSiMUbF",
        "outputId": "ad831819-8e02-4c3e-84fe-cbda8bdb47a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===VERIFY GPU===\n",
            "CUDA IS AVAILABLE: True\n",
            "DEVICE COUNT: 1\n",
            "DEVICE NAME: Tesla T4\n",
            "Number of GPUs: 1\n",
            "GPU Name: Tesla T4\n",
            "GPU Memory Allocated: 0 bytes\n",
            "GPU Memory Cached: 0 bytes\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 492kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.55MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.14MB/s]\n",
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "TRAIN SET LENGTH: 60000\n",
            "TEST SET LENGTH: 10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.298679\n",
            "Train Epoch: 0 [400/60000 (1%)]\tLoss: 2.297248\n",
            "Train Epoch: 0 [800/60000 (1%)]\tLoss: 2.288051\n",
            "Train Epoch: 0 [1200/60000 (2%)]\tLoss: 2.285641\n",
            "Train Epoch: 0 [1600/60000 (3%)]\tLoss: 2.078937\n",
            "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 1.997338\n",
            "Train Epoch: 0 [2400/60000 (4%)]\tLoss: 1.923353\n",
            "Train Epoch: 0 [2800/60000 (5%)]\tLoss: 1.421607\n",
            "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 1.374767\n",
            "Train Epoch: 0 [3600/60000 (6%)]\tLoss: 1.499787\n",
            "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.818942\n",
            "Train Epoch: 0 [4400/60000 (7%)]\tLoss: 0.714031\n",
            "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 0.569233\n",
            "Train Epoch: 0 [5200/60000 (9%)]\tLoss: 0.679172\n",
            "Train Epoch: 0 [5600/60000 (9%)]\tLoss: 0.899922\n",
            "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 1.296022\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.245166\n",
            "Train Epoch: 0 [6800/60000 (11%)]\tLoss: 0.521754\n",
            "Train Epoch: 0 [7200/60000 (12%)]\tLoss: 0.520250\n",
            "Train Epoch: 0 [7600/60000 (13%)]\tLoss: 0.436735\n",
            "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.580003\n",
            "Train Epoch: 0 [8400/60000 (14%)]\tLoss: 0.544996\n",
            "Train Epoch: 0 [8800/60000 (15%)]\tLoss: 0.786994\n",
            "Train Epoch: 0 [9200/60000 (15%)]\tLoss: 0.417811\n",
            "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.103505\n",
            "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.462281\n",
            "Train Epoch: 0 [10400/60000 (17%)]\tLoss: 0.542174\n",
            "Train Epoch: 0 [10800/60000 (18%)]\tLoss: 0.103517\n",
            "Train Epoch: 0 [11200/60000 (19%)]\tLoss: 0.602760\n",
            "Train Epoch: 0 [11600/60000 (19%)]\tLoss: 0.316359\n",
            "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.165215\n",
            "Train Epoch: 0 [12400/60000 (21%)]\tLoss: 0.079487\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.244728\n",
            "Train Epoch: 0 [13200/60000 (22%)]\tLoss: 0.645813\n",
            "Train Epoch: 0 [13600/60000 (23%)]\tLoss: 0.554206\n",
            "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.421576\n",
            "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 0.196762\n",
            "Train Epoch: 0 [14800/60000 (25%)]\tLoss: 0.112496\n",
            "Train Epoch: 0 [15200/60000 (25%)]\tLoss: 0.012672\n",
            "Train Epoch: 0 [15600/60000 (26%)]\tLoss: 0.165869\n",
            "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.161170\n",
            "Train Epoch: 0 [16400/60000 (27%)]\tLoss: 0.021320\n",
            "Train Epoch: 0 [16800/60000 (28%)]\tLoss: 0.150421\n",
            "Train Epoch: 0 [17200/60000 (29%)]\tLoss: 0.239448\n",
            "Train Epoch: 0 [17600/60000 (29%)]\tLoss: 0.146241\n",
            "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.058249\n",
            "Train Epoch: 0 [18400/60000 (31%)]\tLoss: 0.898756\n",
            "Train Epoch: 0 [18800/60000 (31%)]\tLoss: 0.550730\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.685165\n",
            "Train Epoch: 0 [19600/60000 (33%)]\tLoss: 0.238250\n",
            "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.103267\n",
            "Train Epoch: 0 [20400/60000 (34%)]\tLoss: 0.174342\n",
            "Train Epoch: 0 [20800/60000 (35%)]\tLoss: 0.071400\n",
            "Train Epoch: 0 [21200/60000 (35%)]\tLoss: 0.036186\n",
            "Train Epoch: 0 [21600/60000 (36%)]\tLoss: 0.076579\n",
            "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.137026\n",
            "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.170279\n",
            "Train Epoch: 0 [22800/60000 (38%)]\tLoss: 0.012367\n",
            "Train Epoch: 0 [23200/60000 (39%)]\tLoss: 0.536538\n",
            "Train Epoch: 0 [23600/60000 (39%)]\tLoss: 0.035241\n",
            "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.042336\n",
            "Train Epoch: 0 [24400/60000 (41%)]\tLoss: 0.206692\n",
            "Train Epoch: 0 [24800/60000 (41%)]\tLoss: 0.046614\n",
            "Train Epoch: 0 [25200/60000 (42%)]\tLoss: 0.361651\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.068498\n",
            "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.076658\n",
            "Train Epoch: 0 [26400/60000 (44%)]\tLoss: 0.086544\n",
            "Train Epoch: 0 [26800/60000 (45%)]\tLoss: 0.723722\n",
            "Train Epoch: 0 [27200/60000 (45%)]\tLoss: 0.091242\n",
            "Train Epoch: 0 [27600/60000 (46%)]\tLoss: 0.116955\n",
            "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.419387\n",
            "Train Epoch: 0 [28400/60000 (47%)]\tLoss: 0.068888\n",
            "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.703013\n",
            "Train Epoch: 0 [29200/60000 (49%)]\tLoss: 0.015919\n",
            "Train Epoch: 0 [29600/60000 (49%)]\tLoss: 0.104593\n",
            "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.092608\n",
            "Train Epoch: 0 [30400/60000 (51%)]\tLoss: 0.197428\n",
            "Train Epoch: 0 [30800/60000 (51%)]\tLoss: 0.186682\n",
            "Train Epoch: 0 [31200/60000 (52%)]\tLoss: 0.349163\n",
            "Train Epoch: 0 [31600/60000 (53%)]\tLoss: 0.300497\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.182122\n",
            "Train Epoch: 0 [32400/60000 (54%)]\tLoss: 0.218003\n",
            "Train Epoch: 0 [32800/60000 (55%)]\tLoss: 0.062563\n",
            "Train Epoch: 0 [33200/60000 (55%)]\tLoss: 0.232186\n",
            "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 0.005050\n",
            "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.151709\n",
            "Train Epoch: 0 [34400/60000 (57%)]\tLoss: 0.295058\n",
            "Train Epoch: 0 [34800/60000 (58%)]\tLoss: 0.222117\n",
            "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.013639\n",
            "Train Epoch: 0 [35600/60000 (59%)]\tLoss: 0.111264\n",
            "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.191550\n",
            "Train Epoch: 0 [36400/60000 (61%)]\tLoss: 0.394564\n",
            "Train Epoch: 0 [36800/60000 (61%)]\tLoss: 0.002433\n",
            "Train Epoch: 0 [37200/60000 (62%)]\tLoss: 0.724347\n",
            "Train Epoch: 0 [37600/60000 (63%)]\tLoss: 0.186484\n",
            "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.146634\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.077613\n",
            "Train Epoch: 0 [38800/60000 (65%)]\tLoss: 0.646107\n",
            "Train Epoch: 0 [39200/60000 (65%)]\tLoss: 0.032555\n",
            "Train Epoch: 0 [39600/60000 (66%)]\tLoss: 0.366293\n",
            "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.012307\n",
            "Train Epoch: 0 [40400/60000 (67%)]\tLoss: 0.176754\n",
            "Train Epoch: 0 [40800/60000 (68%)]\tLoss: 0.187376\n",
            "Train Epoch: 0 [41200/60000 (69%)]\tLoss: 0.101721\n",
            "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.177266\n",
            "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.047541\n",
            "Train Epoch: 0 [42400/60000 (71%)]\tLoss: 0.229569\n",
            "Train Epoch: 0 [42800/60000 (71%)]\tLoss: 0.577223\n",
            "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 0.373932\n",
            "Train Epoch: 0 [43600/60000 (73%)]\tLoss: 0.472240\n",
            "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.100576\n",
            "Train Epoch: 0 [44400/60000 (74%)]\tLoss: 0.057337\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.019807\n",
            "Train Epoch: 0 [45200/60000 (75%)]\tLoss: 0.197421\n",
            "Train Epoch: 0 [45600/60000 (76%)]\tLoss: 0.204897\n",
            "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.661209\n",
            "Train Epoch: 0 [46400/60000 (77%)]\tLoss: 0.058710\n",
            "Train Epoch: 0 [46800/60000 (78%)]\tLoss: 0.276263\n",
            "Train Epoch: 0 [47200/60000 (79%)]\tLoss: 0.350581\n",
            "Train Epoch: 0 [47600/60000 (79%)]\tLoss: 0.254005\n",
            "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.213898\n",
            "Train Epoch: 0 [48400/60000 (81%)]\tLoss: 1.341153\n",
            "Train Epoch: 0 [48800/60000 (81%)]\tLoss: 0.015262\n",
            "Train Epoch: 0 [49200/60000 (82%)]\tLoss: 0.105135\n",
            "Train Epoch: 0 [49600/60000 (83%)]\tLoss: 0.025463\n",
            "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.378632\n",
            "Train Epoch: 0 [50400/60000 (84%)]\tLoss: 0.075928\n",
            "Train Epoch: 0 [50800/60000 (85%)]\tLoss: 0.469740\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.006424\n",
            "Train Epoch: 0 [51600/60000 (86%)]\tLoss: 0.365083\n",
            "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.152833\n",
            "Train Epoch: 0 [52400/60000 (87%)]\tLoss: 0.165692\n",
            "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 0.211053\n",
            "Train Epoch: 0 [53200/60000 (89%)]\tLoss: 0.109750\n",
            "Train Epoch: 0 [53600/60000 (89%)]\tLoss: 0.377512\n",
            "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.000651\n",
            "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.135686\n",
            "Train Epoch: 0 [54800/60000 (91%)]\tLoss: 0.406292\n",
            "Train Epoch: 0 [55200/60000 (92%)]\tLoss: 0.083154\n",
            "Train Epoch: 0 [55600/60000 (93%)]\tLoss: 0.007914\n",
            "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.018347\n",
            "Train Epoch: 0 [56400/60000 (94%)]\tLoss: 0.002553\n",
            "Train Epoch: 0 [56800/60000 (95%)]\tLoss: 0.240551\n",
            "Train Epoch: 0 [57200/60000 (95%)]\tLoss: 0.019505\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.095231\n",
            "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.076523\n",
            "Train Epoch: 0 [58400/60000 (97%)]\tLoss: 0.014807\n",
            "Train Epoch: 0 [58800/60000 (98%)]\tLoss: 0.219420\n",
            "Train Epoch: 0 [59200/60000 (99%)]\tLoss: 0.008176\n",
            "Train Epoch: 0 [59600/60000 (99%)]\tLoss: 0.024348\n",
            "\n",
            "Test set: Average loss: 0.1445, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.061613\n",
            "Train Epoch: 1 [400/60000 (1%)]\tLoss: 0.005634\n",
            "Train Epoch: 1 [800/60000 (1%)]\tLoss: 0.003439\n",
            "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 0.313641\n",
            "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 0.028852\n",
            "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.045458\n",
            "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 0.007523\n",
            "Train Epoch: 1 [2800/60000 (5%)]\tLoss: 0.110841\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.080345\n",
            "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 0.135517\n",
            "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.012855\n",
            "Train Epoch: 1 [4400/60000 (7%)]\tLoss: 0.028613\n",
            "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.026960\n",
            "Train Epoch: 1 [5200/60000 (9%)]\tLoss: 0.494502\n",
            "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 0.085524\n",
            "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.014961\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.160481\n",
            "Train Epoch: 1 [6800/60000 (11%)]\tLoss: 0.007151\n",
            "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.019566\n",
            "Train Epoch: 1 [7600/60000 (13%)]\tLoss: 0.077253\n",
            "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.011088\n",
            "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 0.279438\n",
            "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 0.144692\n",
            "Train Epoch: 1 [9200/60000 (15%)]\tLoss: 0.035468\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.434793\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.034623\n",
            "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.034340\n",
            "Train Epoch: 1 [10800/60000 (18%)]\tLoss: 0.069191\n",
            "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.107379\n",
            "Train Epoch: 1 [11600/60000 (19%)]\tLoss: 0.011494\n",
            "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.025697\n",
            "Train Epoch: 1 [12400/60000 (21%)]\tLoss: 0.189323\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.005926\n",
            "Train Epoch: 1 [13200/60000 (22%)]\tLoss: 0.029599\n",
            "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 0.038882\n",
            "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.248370\n",
            "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.084267\n",
            "Train Epoch: 1 [14800/60000 (25%)]\tLoss: 0.066198\n",
            "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 0.001658\n",
            "Train Epoch: 1 [15600/60000 (26%)]\tLoss: 0.045459\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.032237\n",
            "Train Epoch: 1 [16400/60000 (27%)]\tLoss: 0.067110\n",
            "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 0.012050\n",
            "Train Epoch: 1 [17200/60000 (29%)]\tLoss: 0.031259\n",
            "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.028485\n",
            "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.000898\n",
            "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 0.008452\n",
            "Train Epoch: 1 [18800/60000 (31%)]\tLoss: 0.017963\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.037294\n",
            "Train Epoch: 1 [19600/60000 (33%)]\tLoss: 0.040257\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.112162\n",
            "Train Epoch: 1 [20400/60000 (34%)]\tLoss: 0.003037\n",
            "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.690430\n",
            "Train Epoch: 1 [21200/60000 (35%)]\tLoss: 0.003192\n",
            "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 0.292068\n",
            "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.744181\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.063338\n",
            "Train Epoch: 1 [22800/60000 (38%)]\tLoss: 0.112232\n",
            "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 0.057225\n",
            "Train Epoch: 1 [23600/60000 (39%)]\tLoss: 0.003270\n",
            "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.071292\n",
            "Train Epoch: 1 [24400/60000 (41%)]\tLoss: 0.162955\n",
            "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 0.094180\n",
            "Train Epoch: 1 [25200/60000 (42%)]\tLoss: 0.000692\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.002815\n",
            "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.014074\n",
            "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 0.295444\n",
            "Train Epoch: 1 [26800/60000 (45%)]\tLoss: 0.034286\n",
            "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.003568\n",
            "Train Epoch: 1 [27600/60000 (46%)]\tLoss: 0.276973\n",
            "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.007692\n",
            "Train Epoch: 1 [28400/60000 (47%)]\tLoss: 0.334563\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.023839\n",
            "Train Epoch: 1 [29200/60000 (49%)]\tLoss: 0.168646\n",
            "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 0.132534\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.068635\n",
            "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.079316\n",
            "Train Epoch: 1 [30800/60000 (51%)]\tLoss: 0.213766\n",
            "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 0.136192\n",
            "Train Epoch: 1 [31600/60000 (53%)]\tLoss: 0.043069\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.332040\n",
            "Train Epoch: 1 [32400/60000 (54%)]\tLoss: 0.049724\n",
            "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 0.014675\n",
            "Train Epoch: 1 [33200/60000 (55%)]\tLoss: 0.227506\n",
            "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.166883\n",
            "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.063398\n",
            "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 0.175284\n",
            "Train Epoch: 1 [34800/60000 (58%)]\tLoss: 0.018065\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.107904\n",
            "Train Epoch: 1 [35600/60000 (59%)]\tLoss: 0.108217\n",
            "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.010912\n",
            "Train Epoch: 1 [36400/60000 (61%)]\tLoss: 0.003818\n",
            "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.053971\n",
            "Train Epoch: 1 [37200/60000 (62%)]\tLoss: 0.011446\n",
            "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 0.013826\n",
            "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.008027\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.082661\n",
            "Train Epoch: 1 [38800/60000 (65%)]\tLoss: 0.026652\n",
            "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 0.008812\n",
            "Train Epoch: 1 [39600/60000 (66%)]\tLoss: 0.017295\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.500280\n",
            "Train Epoch: 1 [40400/60000 (67%)]\tLoss: 0.052995\n",
            "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 0.376430\n",
            "Train Epoch: 1 [41200/60000 (69%)]\tLoss: 0.003774\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.002421\n",
            "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.069886\n",
            "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 0.184987\n",
            "Train Epoch: 1 [42800/60000 (71%)]\tLoss: 0.007780\n",
            "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.519026\n",
            "Train Epoch: 1 [43600/60000 (73%)]\tLoss: 0.065589\n",
            "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.006039\n",
            "Train Epoch: 1 [44400/60000 (74%)]\tLoss: 0.003574\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.341365\n",
            "Train Epoch: 1 [45200/60000 (75%)]\tLoss: 0.005888\n",
            "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.028165\n",
            "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.026022\n",
            "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.266476\n",
            "Train Epoch: 1 [46800/60000 (78%)]\tLoss: 0.318109\n",
            "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 0.106574\n",
            "Train Epoch: 1 [47600/60000 (79%)]\tLoss: 0.002666\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.244912\n",
            "Train Epoch: 1 [48400/60000 (81%)]\tLoss: 0.766312\n",
            "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 0.277167\n",
            "Train Epoch: 1 [49200/60000 (82%)]\tLoss: 0.037091\n",
            "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.004463\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.040921\n",
            "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.032846\n",
            "Train Epoch: 1 [50800/60000 (85%)]\tLoss: 0.322317\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.038243\n",
            "Train Epoch: 1 [51600/60000 (86%)]\tLoss: 0.315676\n",
            "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.599082\n",
            "Train Epoch: 1 [52400/60000 (87%)]\tLoss: 0.032805\n",
            "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.004587\n",
            "Train Epoch: 1 [53200/60000 (89%)]\tLoss: 0.099491\n",
            "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 0.012135\n",
            "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.168118\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.004139\n",
            "Train Epoch: 1 [54800/60000 (91%)]\tLoss: 0.048332\n",
            "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.490106\n",
            "Train Epoch: 1 [55600/60000 (93%)]\tLoss: 0.135586\n",
            "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.130246\n",
            "Train Epoch: 1 [56400/60000 (94%)]\tLoss: 0.589277\n",
            "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 0.082855\n",
            "Train Epoch: 1 [57200/60000 (95%)]\tLoss: 0.031924\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.002426\n",
            "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.013256\n",
            "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 0.103927\n",
            "Train Epoch: 1 [58800/60000 (98%)]\tLoss: 0.487152\n",
            "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.171476\n",
            "Train Epoch: 1 [59600/60000 (99%)]\tLoss: 0.353948\n",
            "\n",
            "Test set: Average loss: 0.1065, Accuracy: 9694/10000 (97%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.039165\n",
            "Train Epoch: 2 [400/60000 (1%)]\tLoss: 0.001439\n",
            "Train Epoch: 2 [800/60000 (1%)]\tLoss: 0.121946\n",
            "Train Epoch: 2 [1200/60000 (2%)]\tLoss: 0.003332\n",
            "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.057061\n",
            "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.026956\n",
            "Train Epoch: 2 [2400/60000 (4%)]\tLoss: 0.045444\n",
            "Train Epoch: 2 [2800/60000 (5%)]\tLoss: 0.007034\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.016761\n",
            "Train Epoch: 2 [3600/60000 (6%)]\tLoss: 0.009677\n",
            "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.040836\n",
            "Train Epoch: 2 [4400/60000 (7%)]\tLoss: 0.209892\n",
            "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.096106\n",
            "Train Epoch: 2 [5200/60000 (9%)]\tLoss: 0.274130\n",
            "Train Epoch: 2 [5600/60000 (9%)]\tLoss: 0.010804\n",
            "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.016464\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.002960\n",
            "Train Epoch: 2 [6800/60000 (11%)]\tLoss: 0.001239\n",
            "Train Epoch: 2 [7200/60000 (12%)]\tLoss: 0.000635\n",
            "Train Epoch: 2 [7600/60000 (13%)]\tLoss: 0.012959\n",
            "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.075404\n",
            "Train Epoch: 2 [8400/60000 (14%)]\tLoss: 0.035663\n",
            "Train Epoch: 2 [8800/60000 (15%)]\tLoss: 0.025790\n",
            "Train Epoch: 2 [9200/60000 (15%)]\tLoss: 0.016780\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.004443\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.055735\n",
            "Train Epoch: 2 [10400/60000 (17%)]\tLoss: 0.091890\n",
            "Train Epoch: 2 [10800/60000 (18%)]\tLoss: 0.020738\n",
            "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.123567\n",
            "Train Epoch: 2 [11600/60000 (19%)]\tLoss: 0.045299\n",
            "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.079329\n",
            "Train Epoch: 2 [12400/60000 (21%)]\tLoss: 0.009247\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.032843\n",
            "Train Epoch: 2 [13200/60000 (22%)]\tLoss: 0.058611\n",
            "Train Epoch: 2 [13600/60000 (23%)]\tLoss: 0.198930\n",
            "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.063644\n",
            "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.000393\n",
            "Train Epoch: 2 [14800/60000 (25%)]\tLoss: 0.022823\n",
            "Train Epoch: 2 [15200/60000 (25%)]\tLoss: 0.116859\n",
            "Train Epoch: 2 [15600/60000 (26%)]\tLoss: 0.005337\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.013386\n",
            "Train Epoch: 2 [16400/60000 (27%)]\tLoss: 0.017638\n",
            "Train Epoch: 2 [16800/60000 (28%)]\tLoss: 0.361184\n",
            "Train Epoch: 2 [17200/60000 (29%)]\tLoss: 0.010542\n",
            "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.000430\n",
            "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.017406\n",
            "Train Epoch: 2 [18400/60000 (31%)]\tLoss: 0.109201\n",
            "Train Epoch: 2 [18800/60000 (31%)]\tLoss: 0.013353\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.000853\n",
            "Train Epoch: 2 [19600/60000 (33%)]\tLoss: 0.025720\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.448969\n",
            "Train Epoch: 2 [20400/60000 (34%)]\tLoss: 0.136089\n",
            "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.019844\n",
            "Train Epoch: 2 [21200/60000 (35%)]\tLoss: 0.031529\n",
            "Train Epoch: 2 [21600/60000 (36%)]\tLoss: 0.007544\n",
            "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.001632\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.019957\n",
            "Train Epoch: 2 [22800/60000 (38%)]\tLoss: 0.036218\n",
            "Train Epoch: 2 [23200/60000 (39%)]\tLoss: 0.153454\n",
            "Train Epoch: 2 [23600/60000 (39%)]\tLoss: 0.002929\n",
            "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.006399\n",
            "Train Epoch: 2 [24400/60000 (41%)]\tLoss: 0.013131\n",
            "Train Epoch: 2 [24800/60000 (41%)]\tLoss: 0.281551\n",
            "Train Epoch: 2 [25200/60000 (42%)]\tLoss: 0.011860\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.101251\n",
            "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.000442\n",
            "Train Epoch: 2 [26400/60000 (44%)]\tLoss: 0.278206\n",
            "Train Epoch: 2 [26800/60000 (45%)]\tLoss: 0.040792\n",
            "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.032792\n",
            "Train Epoch: 2 [27600/60000 (46%)]\tLoss: 0.043252\n",
            "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.006995\n",
            "Train Epoch: 2 [28400/60000 (47%)]\tLoss: 0.005187\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.004615\n",
            "Train Epoch: 2 [29200/60000 (49%)]\tLoss: 0.107543\n",
            "Train Epoch: 2 [29600/60000 (49%)]\tLoss: 0.103910\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.002838\n",
            "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.002338\n",
            "Train Epoch: 2 [30800/60000 (51%)]\tLoss: 0.467535\n",
            "Train Epoch: 2 [31200/60000 (52%)]\tLoss: 0.018515\n",
            "Train Epoch: 2 [31600/60000 (53%)]\tLoss: 0.007253\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.190382\n",
            "Train Epoch: 2 [32400/60000 (54%)]\tLoss: 0.003470\n",
            "Train Epoch: 2 [32800/60000 (55%)]\tLoss: 0.007710\n",
            "Train Epoch: 2 [33200/60000 (55%)]\tLoss: 0.073001\n",
            "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.024279\n",
            "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.003531\n",
            "Train Epoch: 2 [34400/60000 (57%)]\tLoss: 0.055264\n",
            "Train Epoch: 2 [34800/60000 (58%)]\tLoss: 0.069701\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.110061\n",
            "Train Epoch: 2 [35600/60000 (59%)]\tLoss: 0.025267\n",
            "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.605258\n",
            "Train Epoch: 2 [36400/60000 (61%)]\tLoss: 0.304140\n",
            "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.021413\n",
            "Train Epoch: 2 [37200/60000 (62%)]\tLoss: 0.000922\n",
            "Train Epoch: 2 [37600/60000 (63%)]\tLoss: 0.195395\n",
            "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.005748\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.002555\n",
            "Train Epoch: 2 [38800/60000 (65%)]\tLoss: 0.424007\n",
            "Train Epoch: 2 [39200/60000 (65%)]\tLoss: 0.000842\n",
            "Train Epoch: 2 [39600/60000 (66%)]\tLoss: 0.112536\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.101961\n",
            "Train Epoch: 2 [40400/60000 (67%)]\tLoss: 0.066840\n",
            "Train Epoch: 2 [40800/60000 (68%)]\tLoss: 0.036399\n",
            "Train Epoch: 2 [41200/60000 (69%)]\tLoss: 0.024625\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.000782\n",
            "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.002427\n",
            "Train Epoch: 2 [42400/60000 (71%)]\tLoss: 0.014308\n",
            "Train Epoch: 2 [42800/60000 (71%)]\tLoss: 0.091494\n",
            "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.249718\n",
            "Train Epoch: 2 [43600/60000 (73%)]\tLoss: 0.049324\n",
            "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.042145\n",
            "Train Epoch: 2 [44400/60000 (74%)]\tLoss: 0.005343\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.098575\n",
            "Train Epoch: 2 [45200/60000 (75%)]\tLoss: 0.007969\n",
            "Train Epoch: 2 [45600/60000 (76%)]\tLoss: 0.090903\n",
            "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.221906\n",
            "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.018859\n",
            "Train Epoch: 2 [46800/60000 (78%)]\tLoss: 0.079499\n",
            "Train Epoch: 2 [47200/60000 (79%)]\tLoss: 0.047060\n",
            "Train Epoch: 2 [47600/60000 (79%)]\tLoss: 0.029981\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.219009\n",
            "Train Epoch: 2 [48400/60000 (81%)]\tLoss: 0.002351\n",
            "Train Epoch: 2 [48800/60000 (81%)]\tLoss: 0.013270\n",
            "Train Epoch: 2 [49200/60000 (82%)]\tLoss: 0.009453\n",
            "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.002705\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.150567\n",
            "Train Epoch: 2 [50400/60000 (84%)]\tLoss: 0.290667\n",
            "Train Epoch: 2 [50800/60000 (85%)]\tLoss: 0.018670\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.439234\n",
            "Train Epoch: 2 [51600/60000 (86%)]\tLoss: 0.036004\n",
            "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.045549\n",
            "Train Epoch: 2 [52400/60000 (87%)]\tLoss: 0.232625\n",
            "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.004698\n",
            "Train Epoch: 2 [53200/60000 (89%)]\tLoss: 0.003312\n",
            "Train Epoch: 2 [53600/60000 (89%)]\tLoss: 0.084782\n",
            "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.163482\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.063204\n",
            "Train Epoch: 2 [54800/60000 (91%)]\tLoss: 0.010973\n",
            "Train Epoch: 2 [55200/60000 (92%)]\tLoss: 0.036130\n",
            "Train Epoch: 2 [55600/60000 (93%)]\tLoss: 0.014839\n",
            "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.443543\n",
            "Train Epoch: 2 [56400/60000 (94%)]\tLoss: 0.064177\n",
            "Train Epoch: 2 [56800/60000 (95%)]\tLoss: 0.027115\n",
            "Train Epoch: 2 [57200/60000 (95%)]\tLoss: 0.001157\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.114394\n",
            "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.018256\n",
            "Train Epoch: 2 [58400/60000 (97%)]\tLoss: 0.015846\n",
            "Train Epoch: 2 [58800/60000 (98%)]\tLoss: 0.002378\n",
            "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.090405\n",
            "Train Epoch: 2 [59600/60000 (99%)]\tLoss: 0.276397\n",
            "\n",
            "Test set: Average loss: 0.0950, Accuracy: 9734/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.005525\n",
            "Train Epoch: 3 [400/60000 (1%)]\tLoss: 0.078358\n",
            "Train Epoch: 3 [800/60000 (1%)]\tLoss: 0.006297\n",
            "Train Epoch: 3 [1200/60000 (2%)]\tLoss: 0.015501\n",
            "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.271579\n",
            "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.175820\n",
            "Train Epoch: 3 [2400/60000 (4%)]\tLoss: 0.000645\n",
            "Train Epoch: 3 [2800/60000 (5%)]\tLoss: 0.035865\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.614809\n",
            "Train Epoch: 3 [3600/60000 (6%)]\tLoss: 0.007053\n",
            "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.005086\n",
            "Train Epoch: 3 [4400/60000 (7%)]\tLoss: 0.015774\n",
            "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.011825\n",
            "Train Epoch: 3 [5200/60000 (9%)]\tLoss: 0.001611\n",
            "Train Epoch: 3 [5600/60000 (9%)]\tLoss: 0.067719\n",
            "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.000286\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.009715\n",
            "Train Epoch: 3 [6800/60000 (11%)]\tLoss: 0.075556\n",
            "Train Epoch: 3 [7200/60000 (12%)]\tLoss: 0.109667\n",
            "Train Epoch: 3 [7600/60000 (13%)]\tLoss: 0.001143\n",
            "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.038146\n",
            "Train Epoch: 3 [8400/60000 (14%)]\tLoss: 0.036197\n",
            "Train Epoch: 3 [8800/60000 (15%)]\tLoss: 0.008648\n",
            "Train Epoch: 3 [9200/60000 (15%)]\tLoss: 0.024580\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.082856\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.007001\n",
            "Train Epoch: 3 [10400/60000 (17%)]\tLoss: 0.014292\n",
            "Train Epoch: 3 [10800/60000 (18%)]\tLoss: 0.009451\n",
            "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.022399\n",
            "Train Epoch: 3 [11600/60000 (19%)]\tLoss: 0.006124\n",
            "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.002990\n",
            "Train Epoch: 3 [12400/60000 (21%)]\tLoss: 0.000171\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.005089\n",
            "Train Epoch: 3 [13200/60000 (22%)]\tLoss: 0.001699\n",
            "Train Epoch: 3 [13600/60000 (23%)]\tLoss: 0.034264\n",
            "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.007768\n",
            "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.000638\n",
            "Train Epoch: 3 [14800/60000 (25%)]\tLoss: 0.004895\n",
            "Train Epoch: 3 [15200/60000 (25%)]\tLoss: 0.000945\n",
            "Train Epoch: 3 [15600/60000 (26%)]\tLoss: 0.108701\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.083638\n",
            "Train Epoch: 3 [16400/60000 (27%)]\tLoss: 0.196286\n",
            "Train Epoch: 3 [16800/60000 (28%)]\tLoss: 0.098648\n",
            "Train Epoch: 3 [17200/60000 (29%)]\tLoss: 0.000607\n",
            "Train Epoch: 3 [17600/60000 (29%)]\tLoss: 0.001475\n",
            "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.086847\n",
            "Train Epoch: 3 [18400/60000 (31%)]\tLoss: 0.064552\n",
            "Train Epoch: 3 [18800/60000 (31%)]\tLoss: 0.009000\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.161440\n",
            "Train Epoch: 3 [19600/60000 (33%)]\tLoss: 0.009999\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.270954\n",
            "Train Epoch: 3 [20400/60000 (34%)]\tLoss: 0.002457\n",
            "Train Epoch: 3 [20800/60000 (35%)]\tLoss: 0.121555\n",
            "Train Epoch: 3 [21200/60000 (35%)]\tLoss: 0.017579\n",
            "Train Epoch: 3 [21600/60000 (36%)]\tLoss: 0.022588\n",
            "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.000608\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.034009\n",
            "Train Epoch: 3 [22800/60000 (38%)]\tLoss: 0.446940\n",
            "Train Epoch: 3 [23200/60000 (39%)]\tLoss: 0.018597\n",
            "Train Epoch: 3 [23600/60000 (39%)]\tLoss: 0.000759\n",
            "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.150491\n",
            "Train Epoch: 3 [24400/60000 (41%)]\tLoss: 0.103237\n",
            "Train Epoch: 3 [24800/60000 (41%)]\tLoss: 0.024202\n",
            "Train Epoch: 3 [25200/60000 (42%)]\tLoss: 0.005477\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.000330\n",
            "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.046424\n",
            "Train Epoch: 3 [26400/60000 (44%)]\tLoss: 0.008267\n",
            "Train Epoch: 3 [26800/60000 (45%)]\tLoss: 0.017584\n",
            "Train Epoch: 3 [27200/60000 (45%)]\tLoss: 0.000710\n",
            "Train Epoch: 3 [27600/60000 (46%)]\tLoss: 0.104183\n",
            "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.001672\n",
            "Train Epoch: 3 [28400/60000 (47%)]\tLoss: 0.002214\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.005968\n",
            "Train Epoch: 3 [29200/60000 (49%)]\tLoss: 0.006254\n",
            "Train Epoch: 3 [29600/60000 (49%)]\tLoss: 0.020937\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.554062\n",
            "Train Epoch: 3 [30400/60000 (51%)]\tLoss: 0.054526\n",
            "Train Epoch: 3 [30800/60000 (51%)]\tLoss: 0.025004\n",
            "Train Epoch: 3 [31200/60000 (52%)]\tLoss: 0.016810\n",
            "Train Epoch: 3 [31600/60000 (53%)]\tLoss: 0.000380\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.129056\n",
            "Train Epoch: 3 [32400/60000 (54%)]\tLoss: 0.008539\n",
            "Train Epoch: 3 [32800/60000 (55%)]\tLoss: 0.065278\n",
            "Train Epoch: 3 [33200/60000 (55%)]\tLoss: 0.009291\n",
            "Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.006840\n",
            "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.120281\n",
            "Train Epoch: 3 [34400/60000 (57%)]\tLoss: 0.001481\n",
            "Train Epoch: 3 [34800/60000 (58%)]\tLoss: 0.030291\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.417578\n",
            "Train Epoch: 3 [35600/60000 (59%)]\tLoss: 0.000584\n",
            "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.027257\n",
            "Train Epoch: 3 [36400/60000 (61%)]\tLoss: 0.016483\n",
            "Train Epoch: 3 [36800/60000 (61%)]\tLoss: 0.020023\n",
            "Train Epoch: 3 [37200/60000 (62%)]\tLoss: 0.003317\n",
            "Train Epoch: 3 [37600/60000 (63%)]\tLoss: 0.084371\n",
            "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.004036\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.060713\n",
            "Train Epoch: 3 [38800/60000 (65%)]\tLoss: 0.014299\n",
            "Train Epoch: 3 [39200/60000 (65%)]\tLoss: 0.010642\n",
            "Train Epoch: 3 [39600/60000 (66%)]\tLoss: 0.006817\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.003584\n",
            "Train Epoch: 3 [40400/60000 (67%)]\tLoss: 0.020724\n",
            "Train Epoch: 3 [40800/60000 (68%)]\tLoss: 0.004001\n",
            "Train Epoch: 3 [41200/60000 (69%)]\tLoss: 0.001785\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.000055\n",
            "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.024402\n",
            "Train Epoch: 3 [42400/60000 (71%)]\tLoss: 0.087087\n",
            "Train Epoch: 3 [42800/60000 (71%)]\tLoss: 0.000057\n",
            "Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.003178\n",
            "Train Epoch: 3 [43600/60000 (73%)]\tLoss: 0.013570\n",
            "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.009116\n",
            "Train Epoch: 3 [44400/60000 (74%)]\tLoss: 0.244497\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.319207\n",
            "Train Epoch: 3 [45200/60000 (75%)]\tLoss: 0.151203\n",
            "Train Epoch: 3 [45600/60000 (76%)]\tLoss: 0.011556\n",
            "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.040603\n",
            "Train Epoch: 3 [46400/60000 (77%)]\tLoss: 0.499476\n",
            "Train Epoch: 3 [46800/60000 (78%)]\tLoss: 0.036714\n",
            "Train Epoch: 3 [47200/60000 (79%)]\tLoss: 0.137622\n",
            "Train Epoch: 3 [47600/60000 (79%)]\tLoss: 0.001171\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.005504\n",
            "Train Epoch: 3 [48400/60000 (81%)]\tLoss: 0.023252\n",
            "Train Epoch: 3 [48800/60000 (81%)]\tLoss: 0.000415\n",
            "Train Epoch: 3 [49200/60000 (82%)]\tLoss: 0.065787\n",
            "Train Epoch: 3 [49600/60000 (83%)]\tLoss: 0.095398\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.000364\n",
            "Train Epoch: 3 [50400/60000 (84%)]\tLoss: 0.213032\n",
            "Train Epoch: 3 [50800/60000 (85%)]\tLoss: 0.244288\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.007423\n",
            "Train Epoch: 3 [51600/60000 (86%)]\tLoss: 0.000098\n",
            "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.004611\n",
            "Train Epoch: 3 [52400/60000 (87%)]\tLoss: 0.177720\n",
            "Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.020570\n",
            "Train Epoch: 3 [53200/60000 (89%)]\tLoss: 0.003585\n",
            "Train Epoch: 3 [53600/60000 (89%)]\tLoss: 0.028474\n",
            "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.051050\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.010671\n",
            "Train Epoch: 3 [54800/60000 (91%)]\tLoss: 0.069951\n",
            "Train Epoch: 3 [55200/60000 (92%)]\tLoss: 0.000389\n",
            "Train Epoch: 3 [55600/60000 (93%)]\tLoss: 0.000358\n",
            "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.026545\n",
            "Train Epoch: 3 [56400/60000 (94%)]\tLoss: 0.000013\n",
            "Train Epoch: 3 [56800/60000 (95%)]\tLoss: 0.000742\n",
            "Train Epoch: 3 [57200/60000 (95%)]\tLoss: 0.000987\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.234890\n",
            "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.025871\n",
            "Train Epoch: 3 [58400/60000 (97%)]\tLoss: 0.028418\n",
            "Train Epoch: 3 [58800/60000 (98%)]\tLoss: 0.154354\n",
            "Train Epoch: 3 [59200/60000 (99%)]\tLoss: 0.000459\n",
            "Train Epoch: 3 [59600/60000 (99%)]\tLoss: 0.042783\n",
            "\n",
            "Test set: Average loss: 0.0886, Accuracy: 9779/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000858\n",
            "Train Epoch: 4 [400/60000 (1%)]\tLoss: 0.021071\n",
            "Train Epoch: 4 [800/60000 (1%)]\tLoss: 0.088494\n",
            "Train Epoch: 4 [1200/60000 (2%)]\tLoss: 0.169509\n",
            "Train Epoch: 4 [1600/60000 (3%)]\tLoss: 0.202599\n",
            "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.151004\n",
            "Train Epoch: 4 [2400/60000 (4%)]\tLoss: 0.002622\n",
            "Train Epoch: 4 [2800/60000 (5%)]\tLoss: 0.002075\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.026942\n",
            "Train Epoch: 4 [3600/60000 (6%)]\tLoss: 0.000743\n",
            "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.000904\n",
            "Train Epoch: 4 [4400/60000 (7%)]\tLoss: 0.004993\n",
            "Train Epoch: 4 [4800/60000 (8%)]\tLoss: 0.332506\n",
            "Train Epoch: 4 [5200/60000 (9%)]\tLoss: 0.004131\n",
            "Train Epoch: 4 [5600/60000 (9%)]\tLoss: 0.001067\n",
            "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.000507\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000776\n",
            "Train Epoch: 4 [6800/60000 (11%)]\tLoss: 0.020754\n",
            "Train Epoch: 4 [7200/60000 (12%)]\tLoss: 0.021491\n",
            "Train Epoch: 4 [7600/60000 (13%)]\tLoss: 0.000666\n",
            "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.001592\n",
            "Train Epoch: 4 [8400/60000 (14%)]\tLoss: 0.056520\n",
            "Train Epoch: 4 [8800/60000 (15%)]\tLoss: 0.031381\n",
            "Train Epoch: 4 [9200/60000 (15%)]\tLoss: 0.411619\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.008590\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.001115\n",
            "Train Epoch: 4 [10400/60000 (17%)]\tLoss: 0.067985\n",
            "Train Epoch: 4 [10800/60000 (18%)]\tLoss: 0.004136\n",
            "Train Epoch: 4 [11200/60000 (19%)]\tLoss: 0.392255\n",
            "Train Epoch: 4 [11600/60000 (19%)]\tLoss: 0.000504\n",
            "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.000188\n",
            "Train Epoch: 4 [12400/60000 (21%)]\tLoss: 0.275442\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.031663\n",
            "Train Epoch: 4 [13200/60000 (22%)]\tLoss: 0.006563\n",
            "Train Epoch: 4 [13600/60000 (23%)]\tLoss: 0.000267\n",
            "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.051014\n",
            "Train Epoch: 4 [14400/60000 (24%)]\tLoss: 0.000760\n",
            "Train Epoch: 4 [14800/60000 (25%)]\tLoss: 0.000197\n",
            "Train Epoch: 4 [15200/60000 (25%)]\tLoss: 0.017233\n",
            "Train Epoch: 4 [15600/60000 (26%)]\tLoss: 0.026760\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.000161\n",
            "Train Epoch: 4 [16400/60000 (27%)]\tLoss: 0.133494\n",
            "Train Epoch: 4 [16800/60000 (28%)]\tLoss: 0.007819\n",
            "Train Epoch: 4 [17200/60000 (29%)]\tLoss: 0.000394\n",
            "Train Epoch: 4 [17600/60000 (29%)]\tLoss: 0.001214\n",
            "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.004523\n",
            "Train Epoch: 4 [18400/60000 (31%)]\tLoss: 0.000296\n",
            "Train Epoch: 4 [18800/60000 (31%)]\tLoss: 0.302309\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.015206\n",
            "Train Epoch: 4 [19600/60000 (33%)]\tLoss: 0.000040\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.019139\n",
            "Train Epoch: 4 [20400/60000 (34%)]\tLoss: 0.019766\n",
            "Train Epoch: 4 [20800/60000 (35%)]\tLoss: 0.037002\n",
            "Train Epoch: 4 [21200/60000 (35%)]\tLoss: 0.080321\n",
            "Train Epoch: 4 [21600/60000 (36%)]\tLoss: 0.004871\n",
            "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.001574\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.000627\n",
            "Train Epoch: 4 [22800/60000 (38%)]\tLoss: 0.003210\n",
            "Train Epoch: 4 [23200/60000 (39%)]\tLoss: 0.001261\n",
            "Train Epoch: 4 [23600/60000 (39%)]\tLoss: 0.032610\n",
            "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.008814\n",
            "Train Epoch: 4 [24400/60000 (41%)]\tLoss: 0.003057\n",
            "Train Epoch: 4 [24800/60000 (41%)]\tLoss: 0.044823\n",
            "Train Epoch: 4 [25200/60000 (42%)]\tLoss: 0.005793\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.111741\n",
            "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.021046\n",
            "Train Epoch: 4 [26400/60000 (44%)]\tLoss: 0.009352\n",
            "Train Epoch: 4 [26800/60000 (45%)]\tLoss: 0.069389\n",
            "Train Epoch: 4 [27200/60000 (45%)]\tLoss: 0.009144\n",
            "Train Epoch: 4 [27600/60000 (46%)]\tLoss: 0.012425\n",
            "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.001634\n",
            "Train Epoch: 4 [28400/60000 (47%)]\tLoss: 0.001458\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.018909\n",
            "Train Epoch: 4 [29200/60000 (49%)]\tLoss: 0.143693\n",
            "Train Epoch: 4 [29600/60000 (49%)]\tLoss: 0.144988\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.034143\n",
            "Train Epoch: 4 [30400/60000 (51%)]\tLoss: 0.005588\n",
            "Train Epoch: 4 [30800/60000 (51%)]\tLoss: 0.276205\n",
            "Train Epoch: 4 [31200/60000 (52%)]\tLoss: 0.055755\n",
            "Train Epoch: 4 [31600/60000 (53%)]\tLoss: 0.176671\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.005946\n",
            "Train Epoch: 4 [32400/60000 (54%)]\tLoss: 0.000409\n",
            "Train Epoch: 4 [32800/60000 (55%)]\tLoss: 0.000652\n",
            "Train Epoch: 4 [33200/60000 (55%)]\tLoss: 0.002966\n",
            "Train Epoch: 4 [33600/60000 (56%)]\tLoss: 0.004266\n",
            "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.006553\n",
            "Train Epoch: 4 [34400/60000 (57%)]\tLoss: 0.000613\n",
            "Train Epoch: 4 [34800/60000 (58%)]\tLoss: 0.076826\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.006878\n",
            "Train Epoch: 4 [35600/60000 (59%)]\tLoss: 0.003601\n",
            "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.001309\n",
            "Train Epoch: 4 [36400/60000 (61%)]\tLoss: 0.001681\n",
            "Train Epoch: 4 [36800/60000 (61%)]\tLoss: 0.017063\n",
            "Train Epoch: 4 [37200/60000 (62%)]\tLoss: 0.000106\n",
            "Train Epoch: 4 [37600/60000 (63%)]\tLoss: 0.608407\n",
            "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.000519\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000027\n",
            "Train Epoch: 4 [38800/60000 (65%)]\tLoss: 0.001351\n",
            "Train Epoch: 4 [39200/60000 (65%)]\tLoss: 0.002159\n",
            "Train Epoch: 4 [39600/60000 (66%)]\tLoss: 0.025890\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.005484\n",
            "Train Epoch: 4 [40400/60000 (67%)]\tLoss: 0.000617\n",
            "Train Epoch: 4 [40800/60000 (68%)]\tLoss: 0.136691\n",
            "Train Epoch: 4 [41200/60000 (69%)]\tLoss: 0.011048\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.035313\n",
            "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.000390\n",
            "Train Epoch: 4 [42400/60000 (71%)]\tLoss: 0.173437\n",
            "Train Epoch: 4 [42800/60000 (71%)]\tLoss: 0.008443\n",
            "Train Epoch: 4 [43200/60000 (72%)]\tLoss: 0.001530\n",
            "Train Epoch: 4 [43600/60000 (73%)]\tLoss: 0.001414\n",
            "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.021987\n",
            "Train Epoch: 4 [44400/60000 (74%)]\tLoss: 0.000026\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.003145\n",
            "Train Epoch: 4 [45200/60000 (75%)]\tLoss: 0.000802\n",
            "Train Epoch: 4 [45600/60000 (76%)]\tLoss: 0.006779\n",
            "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.089530\n",
            "Train Epoch: 4 [46400/60000 (77%)]\tLoss: 0.473777\n",
            "Train Epoch: 4 [46800/60000 (78%)]\tLoss: 0.107940\n",
            "Train Epoch: 4 [47200/60000 (79%)]\tLoss: 0.014620\n",
            "Train Epoch: 4 [47600/60000 (79%)]\tLoss: 0.005816\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.000349\n",
            "Train Epoch: 4 [48400/60000 (81%)]\tLoss: 0.273167\n",
            "Train Epoch: 4 [48800/60000 (81%)]\tLoss: 0.000224\n",
            "Train Epoch: 4 [49200/60000 (82%)]\tLoss: 0.001357\n",
            "Train Epoch: 4 [49600/60000 (83%)]\tLoss: 0.005683\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.056456\n",
            "Train Epoch: 4 [50400/60000 (84%)]\tLoss: 0.300203\n",
            "Train Epoch: 4 [50800/60000 (85%)]\tLoss: 0.226572\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.002477\n",
            "Train Epoch: 4 [51600/60000 (86%)]\tLoss: 0.023831\n",
            "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.000671\n",
            "Train Epoch: 4 [52400/60000 (87%)]\tLoss: 0.209674\n",
            "Train Epoch: 4 [52800/60000 (88%)]\tLoss: 0.255980\n",
            "Train Epoch: 4 [53200/60000 (89%)]\tLoss: 0.010182\n",
            "Train Epoch: 4 [53600/60000 (89%)]\tLoss: 0.001806\n",
            "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.018486\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.002216\n",
            "Train Epoch: 4 [54800/60000 (91%)]\tLoss: 0.059050\n",
            "Train Epoch: 4 [55200/60000 (92%)]\tLoss: 0.000612\n",
            "Train Epoch: 4 [55600/60000 (93%)]\tLoss: 0.143154\n",
            "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.056378\n",
            "Train Epoch: 4 [56400/60000 (94%)]\tLoss: 0.296084\n",
            "Train Epoch: 4 [56800/60000 (95%)]\tLoss: 0.001107\n",
            "Train Epoch: 4 [57200/60000 (95%)]\tLoss: 0.001293\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.626135\n",
            "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.002640\n",
            "Train Epoch: 4 [58400/60000 (97%)]\tLoss: 0.002530\n",
            "Train Epoch: 4 [58800/60000 (98%)]\tLoss: 0.004956\n",
            "Train Epoch: 4 [59200/60000 (99%)]\tLoss: 0.204202\n",
            "Train Epoch: 4 [59600/60000 (99%)]\tLoss: 0.198138\n",
            "\n",
            "Test set: Average loss: 0.0718, Accuracy: 9810/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.017820\n",
            "Train Epoch: 5 [400/60000 (1%)]\tLoss: 0.000666\n",
            "Train Epoch: 5 [800/60000 (1%)]\tLoss: 0.006316\n",
            "Train Epoch: 5 [1200/60000 (2%)]\tLoss: 0.004508\n",
            "Train Epoch: 5 [1600/60000 (3%)]\tLoss: 0.001116\n",
            "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.094831\n",
            "Train Epoch: 5 [2400/60000 (4%)]\tLoss: 0.008194\n",
            "Train Epoch: 5 [2800/60000 (5%)]\tLoss: 0.000499\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.049383\n",
            "Train Epoch: 5 [3600/60000 (6%)]\tLoss: 0.240429\n",
            "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.000826\n",
            "Train Epoch: 5 [4400/60000 (7%)]\tLoss: 0.155619\n",
            "Train Epoch: 5 [4800/60000 (8%)]\tLoss: 0.153316\n",
            "Train Epoch: 5 [5200/60000 (9%)]\tLoss: 0.001464\n",
            "Train Epoch: 5 [5600/60000 (9%)]\tLoss: 0.044156\n",
            "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.001304\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000401\n",
            "Train Epoch: 5 [6800/60000 (11%)]\tLoss: 0.000124\n",
            "Train Epoch: 5 [7200/60000 (12%)]\tLoss: 0.001381\n",
            "Train Epoch: 5 [7600/60000 (13%)]\tLoss: 0.010985\n",
            "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.002006\n",
            "Train Epoch: 5 [8400/60000 (14%)]\tLoss: 0.000530\n",
            "Train Epoch: 5 [8800/60000 (15%)]\tLoss: 0.001071\n",
            "Train Epoch: 5 [9200/60000 (15%)]\tLoss: 0.000307\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.000581\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.004281\n",
            "Train Epoch: 5 [10400/60000 (17%)]\tLoss: 0.000564\n",
            "Train Epoch: 5 [10800/60000 (18%)]\tLoss: 0.001112\n",
            "Train Epoch: 5 [11200/60000 (19%)]\tLoss: 0.003477\n",
            "Train Epoch: 5 [11600/60000 (19%)]\tLoss: 0.002416\n",
            "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.012971\n",
            "Train Epoch: 5 [12400/60000 (21%)]\tLoss: 0.000188\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 5 [13200/60000 (22%)]\tLoss: 0.001629\n",
            "Train Epoch: 5 [13600/60000 (23%)]\tLoss: 0.011471\n",
            "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.000003\n",
            "Train Epoch: 5 [14400/60000 (24%)]\tLoss: 0.001653\n",
            "Train Epoch: 5 [14800/60000 (25%)]\tLoss: 0.002070\n",
            "Train Epoch: 5 [15200/60000 (25%)]\tLoss: 0.000598\n",
            "Train Epoch: 5 [15600/60000 (26%)]\tLoss: 0.028329\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.001560\n",
            "Train Epoch: 5 [16400/60000 (27%)]\tLoss: 0.000420\n",
            "Train Epoch: 5 [16800/60000 (28%)]\tLoss: 0.001262\n",
            "Train Epoch: 5 [17200/60000 (29%)]\tLoss: 0.205160\n",
            "Train Epoch: 5 [17600/60000 (29%)]\tLoss: 0.000776\n",
            "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.000008\n",
            "Train Epoch: 5 [18400/60000 (31%)]\tLoss: 0.000211\n",
            "Train Epoch: 5 [18800/60000 (31%)]\tLoss: 0.000118\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.000016\n",
            "Train Epoch: 5 [19600/60000 (33%)]\tLoss: 0.035506\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.016339\n",
            "Train Epoch: 5 [20400/60000 (34%)]\tLoss: 0.023668\n",
            "Train Epoch: 5 [20800/60000 (35%)]\tLoss: 0.000002\n",
            "Train Epoch: 5 [21200/60000 (35%)]\tLoss: 0.239794\n",
            "Train Epoch: 5 [21600/60000 (36%)]\tLoss: 0.000246\n",
            "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.014140\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.031140\n",
            "Train Epoch: 5 [22800/60000 (38%)]\tLoss: 0.088499\n",
            "Train Epoch: 5 [23200/60000 (39%)]\tLoss: 0.005547\n",
            "Train Epoch: 5 [23600/60000 (39%)]\tLoss: 0.055364\n",
            "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.006515\n",
            "Train Epoch: 5 [24400/60000 (41%)]\tLoss: 0.002182\n",
            "Train Epoch: 5 [24800/60000 (41%)]\tLoss: 0.012700\n",
            "Train Epoch: 5 [25200/60000 (42%)]\tLoss: 0.000860\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.007055\n",
            "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.008015\n",
            "Train Epoch: 5 [26400/60000 (44%)]\tLoss: 0.009302\n",
            "Train Epoch: 5 [26800/60000 (45%)]\tLoss: 0.000061\n",
            "Train Epoch: 5 [27200/60000 (45%)]\tLoss: 0.003087\n",
            "Train Epoch: 5 [27600/60000 (46%)]\tLoss: 0.025120\n",
            "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.022382\n",
            "Train Epoch: 5 [28400/60000 (47%)]\tLoss: 0.117412\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.008680\n",
            "Train Epoch: 5 [29200/60000 (49%)]\tLoss: 0.002444\n",
            "Train Epoch: 5 [29600/60000 (49%)]\tLoss: 0.000945\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.037632\n",
            "Train Epoch: 5 [30400/60000 (51%)]\tLoss: 0.068106\n",
            "Train Epoch: 5 [30800/60000 (51%)]\tLoss: 0.011083\n",
            "Train Epoch: 5 [31200/60000 (52%)]\tLoss: 0.000941\n",
            "Train Epoch: 5 [31600/60000 (53%)]\tLoss: 0.005116\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000185\n",
            "Train Epoch: 5 [32400/60000 (54%)]\tLoss: 0.008533\n",
            "Train Epoch: 5 [32800/60000 (55%)]\tLoss: 0.012724\n",
            "Train Epoch: 5 [33200/60000 (55%)]\tLoss: 0.036700\n",
            "Train Epoch: 5 [33600/60000 (56%)]\tLoss: 0.050547\n",
            "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.000467\n",
            "Train Epoch: 5 [34400/60000 (57%)]\tLoss: 0.000197\n",
            "Train Epoch: 5 [34800/60000 (58%)]\tLoss: 0.000190\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.052398\n",
            "Train Epoch: 5 [35600/60000 (59%)]\tLoss: 0.042077\n",
            "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.024820\n",
            "Train Epoch: 5 [36400/60000 (61%)]\tLoss: 0.022732\n",
            "Train Epoch: 5 [36800/60000 (61%)]\tLoss: 0.393893\n",
            "Train Epoch: 5 [37200/60000 (62%)]\tLoss: 0.003867\n",
            "Train Epoch: 5 [37600/60000 (63%)]\tLoss: 0.008525\n",
            "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.000685\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.035863\n",
            "Train Epoch: 5 [38800/60000 (65%)]\tLoss: 0.008654\n",
            "Train Epoch: 5 [39200/60000 (65%)]\tLoss: 0.000147\n",
            "Train Epoch: 5 [39600/60000 (66%)]\tLoss: 0.033828\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.000099\n",
            "Train Epoch: 5 [40400/60000 (67%)]\tLoss: 0.021537\n",
            "Train Epoch: 5 [40800/60000 (68%)]\tLoss: 0.203134\n",
            "Train Epoch: 5 [41200/60000 (69%)]\tLoss: 0.029512\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.000107\n",
            "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.002755\n",
            "Train Epoch: 5 [42400/60000 (71%)]\tLoss: 0.053288\n",
            "Train Epoch: 5 [42800/60000 (71%)]\tLoss: 0.093969\n",
            "Train Epoch: 5 [43200/60000 (72%)]\tLoss: 0.006233\n",
            "Train Epoch: 5 [43600/60000 (73%)]\tLoss: 0.005660\n",
            "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.001803\n",
            "Train Epoch: 5 [44400/60000 (74%)]\tLoss: 0.005643\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000777\n",
            "Train Epoch: 5 [45200/60000 (75%)]\tLoss: 0.001515\n",
            "Train Epoch: 5 [45600/60000 (76%)]\tLoss: 0.028820\n",
            "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.140643\n",
            "Train Epoch: 5 [46400/60000 (77%)]\tLoss: 0.000321\n",
            "Train Epoch: 5 [46800/60000 (78%)]\tLoss: 0.060834\n",
            "Train Epoch: 5 [47200/60000 (79%)]\tLoss: 0.000742\n",
            "Train Epoch: 5 [47600/60000 (79%)]\tLoss: 0.016255\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.004407\n",
            "Train Epoch: 5 [48400/60000 (81%)]\tLoss: 0.087377\n",
            "Train Epoch: 5 [48800/60000 (81%)]\tLoss: 0.001505\n",
            "Train Epoch: 5 [49200/60000 (82%)]\tLoss: 0.000501\n",
            "Train Epoch: 5 [49600/60000 (83%)]\tLoss: 0.000909\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.110637\n",
            "Train Epoch: 5 [50400/60000 (84%)]\tLoss: 0.004417\n",
            "Train Epoch: 5 [50800/60000 (85%)]\tLoss: 0.000103\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.016410\n",
            "Train Epoch: 5 [51600/60000 (86%)]\tLoss: 0.004643\n",
            "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.156748\n",
            "Train Epoch: 5 [52400/60000 (87%)]\tLoss: 0.000825\n",
            "Train Epoch: 5 [52800/60000 (88%)]\tLoss: 0.003586\n",
            "Train Epoch: 5 [53200/60000 (89%)]\tLoss: 0.219958\n",
            "Train Epoch: 5 [53600/60000 (89%)]\tLoss: 0.001709\n",
            "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.000140\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.000860\n",
            "Train Epoch: 5 [54800/60000 (91%)]\tLoss: 0.007761\n",
            "Train Epoch: 5 [55200/60000 (92%)]\tLoss: 0.074705\n",
            "Train Epoch: 5 [55600/60000 (93%)]\tLoss: 0.061555\n",
            "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.007757\n",
            "Train Epoch: 5 [56400/60000 (94%)]\tLoss: 0.000206\n",
            "Train Epoch: 5 [56800/60000 (95%)]\tLoss: 0.159371\n",
            "Train Epoch: 5 [57200/60000 (95%)]\tLoss: 0.000503\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.006413\n",
            "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.181081\n",
            "Train Epoch: 5 [58400/60000 (97%)]\tLoss: 0.017866\n",
            "Train Epoch: 5 [58800/60000 (98%)]\tLoss: 0.092041\n",
            "Train Epoch: 5 [59200/60000 (99%)]\tLoss: 0.034772\n",
            "Train Epoch: 5 [59600/60000 (99%)]\tLoss: 0.274983\n",
            "\n",
            "Test set: Average loss: 0.0951, Accuracy: 9761/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.015712\n",
            "Train Epoch: 6 [400/60000 (1%)]\tLoss: 0.002620\n",
            "Train Epoch: 6 [800/60000 (1%)]\tLoss: 0.000494\n",
            "Train Epoch: 6 [1200/60000 (2%)]\tLoss: 0.000984\n",
            "Train Epoch: 6 [1600/60000 (3%)]\tLoss: 0.013320\n",
            "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.018823\n",
            "Train Epoch: 6 [2400/60000 (4%)]\tLoss: 0.000168\n",
            "Train Epoch: 6 [2800/60000 (5%)]\tLoss: 0.025934\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.000527\n",
            "Train Epoch: 6 [3600/60000 (6%)]\tLoss: 0.005175\n",
            "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.000010\n",
            "Train Epoch: 6 [4400/60000 (7%)]\tLoss: 0.061387\n",
            "Train Epoch: 6 [4800/60000 (8%)]\tLoss: 0.000076\n",
            "Train Epoch: 6 [5200/60000 (9%)]\tLoss: 0.000061\n",
            "Train Epoch: 6 [5600/60000 (9%)]\tLoss: 0.000343\n",
            "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.000661\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000634\n",
            "Train Epoch: 6 [6800/60000 (11%)]\tLoss: 0.000091\n",
            "Train Epoch: 6 [7200/60000 (12%)]\tLoss: 0.000953\n",
            "Train Epoch: 6 [7600/60000 (13%)]\tLoss: 0.001088\n",
            "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.003506\n",
            "Train Epoch: 6 [8400/60000 (14%)]\tLoss: 0.038802\n",
            "Train Epoch: 6 [8800/60000 (15%)]\tLoss: 0.029341\n",
            "Train Epoch: 6 [9200/60000 (15%)]\tLoss: 0.285329\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.008624\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.000083\n",
            "Train Epoch: 6 [10400/60000 (17%)]\tLoss: 0.000070\n",
            "Train Epoch: 6 [10800/60000 (18%)]\tLoss: 0.017549\n",
            "Train Epoch: 6 [11200/60000 (19%)]\tLoss: 0.000640\n",
            "Train Epoch: 6 [11600/60000 (19%)]\tLoss: 0.008652\n",
            "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.137134\n",
            "Train Epoch: 6 [12400/60000 (21%)]\tLoss: 0.000269\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.017947\n",
            "Train Epoch: 6 [13200/60000 (22%)]\tLoss: 0.021086\n",
            "Train Epoch: 6 [13600/60000 (23%)]\tLoss: 0.149339\n",
            "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.000583\n",
            "Train Epoch: 6 [14400/60000 (24%)]\tLoss: 0.002657\n",
            "Train Epoch: 6 [14800/60000 (25%)]\tLoss: 0.009389\n",
            "Train Epoch: 6 [15200/60000 (25%)]\tLoss: 0.000406\n",
            "Train Epoch: 6 [15600/60000 (26%)]\tLoss: 0.044147\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.137842\n",
            "Train Epoch: 6 [16400/60000 (27%)]\tLoss: 0.000844\n",
            "Train Epoch: 6 [16800/60000 (28%)]\tLoss: 0.010992\n",
            "Train Epoch: 6 [17200/60000 (29%)]\tLoss: 0.004536\n",
            "Train Epoch: 6 [17600/60000 (29%)]\tLoss: 0.000122\n",
            "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.017468\n",
            "Train Epoch: 6 [18400/60000 (31%)]\tLoss: 0.000442\n",
            "Train Epoch: 6 [18800/60000 (31%)]\tLoss: 0.072249\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.009073\n",
            "Train Epoch: 6 [19600/60000 (33%)]\tLoss: 0.618461\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.040409\n",
            "Train Epoch: 6 [20400/60000 (34%)]\tLoss: 0.000905\n",
            "Train Epoch: 6 [20800/60000 (35%)]\tLoss: 0.007038\n",
            "Train Epoch: 6 [21200/60000 (35%)]\tLoss: 0.037739\n",
            "Train Epoch: 6 [21600/60000 (36%)]\tLoss: 0.003425\n",
            "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.003366\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.001707\n",
            "Train Epoch: 6 [22800/60000 (38%)]\tLoss: 0.000484\n",
            "Train Epoch: 6 [23200/60000 (39%)]\tLoss: 0.014928\n",
            "Train Epoch: 6 [23600/60000 (39%)]\tLoss: 0.000348\n",
            "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.000416\n",
            "Train Epoch: 6 [24400/60000 (41%)]\tLoss: 0.000683\n",
            "Train Epoch: 6 [24800/60000 (41%)]\tLoss: 0.064538\n",
            "Train Epoch: 6 [25200/60000 (42%)]\tLoss: 0.001492\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000260\n",
            "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.000766\n",
            "Train Epoch: 6 [26400/60000 (44%)]\tLoss: 0.000362\n",
            "Train Epoch: 6 [26800/60000 (45%)]\tLoss: 0.085799\n",
            "Train Epoch: 6 [27200/60000 (45%)]\tLoss: 0.000243\n",
            "Train Epoch: 6 [27600/60000 (46%)]\tLoss: 0.002252\n",
            "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.000213\n",
            "Train Epoch: 6 [28400/60000 (47%)]\tLoss: 0.001748\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.082796\n",
            "Train Epoch: 6 [29200/60000 (49%)]\tLoss: 0.002597\n",
            "Train Epoch: 6 [29600/60000 (49%)]\tLoss: 0.001102\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.001404\n",
            "Train Epoch: 6 [30400/60000 (51%)]\tLoss: 0.280950\n",
            "Train Epoch: 6 [30800/60000 (51%)]\tLoss: 0.038410\n",
            "Train Epoch: 6 [31200/60000 (52%)]\tLoss: 0.015326\n",
            "Train Epoch: 6 [31600/60000 (53%)]\tLoss: 0.030772\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.012588\n",
            "Train Epoch: 6 [32400/60000 (54%)]\tLoss: 0.000015\n",
            "Train Epoch: 6 [32800/60000 (55%)]\tLoss: 0.000151\n",
            "Train Epoch: 6 [33200/60000 (55%)]\tLoss: 0.000443\n",
            "Train Epoch: 6 [33600/60000 (56%)]\tLoss: 0.004208\n",
            "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.020198\n",
            "Train Epoch: 6 [34400/60000 (57%)]\tLoss: 0.000176\n",
            "Train Epoch: 6 [34800/60000 (58%)]\tLoss: 0.001206\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.000629\n",
            "Train Epoch: 6 [35600/60000 (59%)]\tLoss: 0.000722\n",
            "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.002576\n",
            "Train Epoch: 6 [36400/60000 (61%)]\tLoss: 0.225358\n",
            "Train Epoch: 6 [36800/60000 (61%)]\tLoss: 0.000152\n",
            "Train Epoch: 6 [37200/60000 (62%)]\tLoss: 0.001325\n",
            "Train Epoch: 6 [37600/60000 (63%)]\tLoss: 0.000360\n",
            "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.009237\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000350\n",
            "Train Epoch: 6 [38800/60000 (65%)]\tLoss: 0.000230\n",
            "Train Epoch: 6 [39200/60000 (65%)]\tLoss: 0.001466\n",
            "Train Epoch: 6 [39600/60000 (66%)]\tLoss: 0.001958\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.195107\n",
            "Train Epoch: 6 [40400/60000 (67%)]\tLoss: 0.441773\n",
            "Train Epoch: 6 [40800/60000 (68%)]\tLoss: 0.000671\n",
            "Train Epoch: 6 [41200/60000 (69%)]\tLoss: 0.012761\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.000289\n",
            "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.000104\n",
            "Train Epoch: 6 [42400/60000 (71%)]\tLoss: 0.002174\n",
            "Train Epoch: 6 [42800/60000 (71%)]\tLoss: 0.003824\n",
            "Train Epoch: 6 [43200/60000 (72%)]\tLoss: 0.016927\n",
            "Train Epoch: 6 [43600/60000 (73%)]\tLoss: 0.004739\n",
            "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.006120\n",
            "Train Epoch: 6 [44400/60000 (74%)]\tLoss: 0.041389\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000350\n",
            "Train Epoch: 6 [45200/60000 (75%)]\tLoss: 0.054065\n",
            "Train Epoch: 6 [45600/60000 (76%)]\tLoss: 0.001011\n",
            "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.034108\n",
            "Train Epoch: 6 [46400/60000 (77%)]\tLoss: 0.012035\n",
            "Train Epoch: 6 [46800/60000 (78%)]\tLoss: 0.000043\n",
            "Train Epoch: 6 [47200/60000 (79%)]\tLoss: 0.000169\n",
            "Train Epoch: 6 [47600/60000 (79%)]\tLoss: 0.000808\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.000076\n",
            "Train Epoch: 6 [48400/60000 (81%)]\tLoss: 0.011766\n",
            "Train Epoch: 6 [48800/60000 (81%)]\tLoss: 0.134827\n",
            "Train Epoch: 6 [49200/60000 (82%)]\tLoss: 0.000057\n",
            "Train Epoch: 6 [49600/60000 (83%)]\tLoss: 0.000074\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.000411\n",
            "Train Epoch: 6 [50400/60000 (84%)]\tLoss: 0.000176\n",
            "Train Epoch: 6 [50800/60000 (85%)]\tLoss: 0.000005\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.140165\n",
            "Train Epoch: 6 [51600/60000 (86%)]\tLoss: 0.752640\n",
            "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.001059\n",
            "Train Epoch: 6 [52400/60000 (87%)]\tLoss: 0.040379\n",
            "Train Epoch: 6 [52800/60000 (88%)]\tLoss: 0.404189\n",
            "Train Epoch: 6 [53200/60000 (89%)]\tLoss: 0.013841\n",
            "Train Epoch: 6 [53600/60000 (89%)]\tLoss: 0.003484\n",
            "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.001328\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.006707\n",
            "Train Epoch: 6 [54800/60000 (91%)]\tLoss: 0.000036\n",
            "Train Epoch: 6 [55200/60000 (92%)]\tLoss: 0.002519\n",
            "Train Epoch: 6 [55600/60000 (93%)]\tLoss: 0.097782\n",
            "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.004712\n",
            "Train Epoch: 6 [56400/60000 (94%)]\tLoss: 0.003250\n",
            "Train Epoch: 6 [56800/60000 (95%)]\tLoss: 0.000083\n",
            "Train Epoch: 6 [57200/60000 (95%)]\tLoss: 0.001328\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000103\n",
            "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.061145\n",
            "Train Epoch: 6 [58400/60000 (97%)]\tLoss: 0.001219\n",
            "Train Epoch: 6 [58800/60000 (98%)]\tLoss: 0.000447\n",
            "Train Epoch: 6 [59200/60000 (99%)]\tLoss: 0.011874\n",
            "Train Epoch: 6 [59600/60000 (99%)]\tLoss: 0.000531\n",
            "\n",
            "Test set: Average loss: 0.0792, Accuracy: 9796/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.009391\n",
            "Train Epoch: 7 [400/60000 (1%)]\tLoss: 0.001015\n",
            "Train Epoch: 7 [800/60000 (1%)]\tLoss: 0.000693\n",
            "Train Epoch: 7 [1200/60000 (2%)]\tLoss: 0.000005\n",
            "Train Epoch: 7 [1600/60000 (3%)]\tLoss: 0.012711\n",
            "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.000185\n",
            "Train Epoch: 7 [2400/60000 (4%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [2800/60000 (5%)]\tLoss: 0.006444\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.000317\n",
            "Train Epoch: 7 [3600/60000 (6%)]\tLoss: 0.000505\n",
            "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.000153\n",
            "Train Epoch: 7 [4400/60000 (7%)]\tLoss: 0.003894\n",
            "Train Epoch: 7 [4800/60000 (8%)]\tLoss: 0.005907\n",
            "Train Epoch: 7 [5200/60000 (9%)]\tLoss: 0.001329\n",
            "Train Epoch: 7 [5600/60000 (9%)]\tLoss: 0.044358\n",
            "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.102904\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.010767\n",
            "Train Epoch: 7 [6800/60000 (11%)]\tLoss: 0.000224\n",
            "Train Epoch: 7 [7200/60000 (12%)]\tLoss: 0.000131\n",
            "Train Epoch: 7 [7600/60000 (13%)]\tLoss: 0.004184\n",
            "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.019021\n",
            "Train Epoch: 7 [8400/60000 (14%)]\tLoss: 0.008393\n",
            "Train Epoch: 7 [8800/60000 (15%)]\tLoss: 0.003960\n",
            "Train Epoch: 7 [9200/60000 (15%)]\tLoss: 0.034450\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.000930\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.000107\n",
            "Train Epoch: 7 [10400/60000 (17%)]\tLoss: 0.000026\n",
            "Train Epoch: 7 [10800/60000 (18%)]\tLoss: 0.019136\n",
            "Train Epoch: 7 [11200/60000 (19%)]\tLoss: 0.000118\n",
            "Train Epoch: 7 [11600/60000 (19%)]\tLoss: 0.000403\n",
            "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.003414\n",
            "Train Epoch: 7 [12400/60000 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.002602\n",
            "Train Epoch: 7 [13200/60000 (22%)]\tLoss: 0.000491\n",
            "Train Epoch: 7 [13600/60000 (23%)]\tLoss: 0.000326\n",
            "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.000002\n",
            "Train Epoch: 7 [14400/60000 (24%)]\tLoss: 0.001284\n",
            "Train Epoch: 7 [14800/60000 (25%)]\tLoss: 0.000060\n",
            "Train Epoch: 7 [15200/60000 (25%)]\tLoss: 0.000089\n",
            "Train Epoch: 7 [15600/60000 (26%)]\tLoss: 0.064556\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.000090\n",
            "Train Epoch: 7 [16400/60000 (27%)]\tLoss: 0.009917\n",
            "Train Epoch: 7 [16800/60000 (28%)]\tLoss: 0.000963\n",
            "Train Epoch: 7 [17200/60000 (29%)]\tLoss: 0.004376\n",
            "Train Epoch: 7 [17600/60000 (29%)]\tLoss: 0.000090\n",
            "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.000171\n",
            "Train Epoch: 7 [18400/60000 (31%)]\tLoss: 0.000047\n",
            "Train Epoch: 7 [18800/60000 (31%)]\tLoss: 0.010721\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000123\n",
            "Train Epoch: 7 [19600/60000 (33%)]\tLoss: 0.000348\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.000152\n",
            "Train Epoch: 7 [20400/60000 (34%)]\tLoss: 0.170327\n",
            "Train Epoch: 7 [20800/60000 (35%)]\tLoss: 0.011707\n",
            "Train Epoch: 7 [21200/60000 (35%)]\tLoss: 0.000003\n",
            "Train Epoch: 7 [21600/60000 (36%)]\tLoss: 0.239485\n",
            "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.003761\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.004289\n",
            "Train Epoch: 7 [22800/60000 (38%)]\tLoss: 0.002222\n",
            "Train Epoch: 7 [23200/60000 (39%)]\tLoss: 0.000986\n",
            "Train Epoch: 7 [23600/60000 (39%)]\tLoss: 0.000214\n",
            "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.000157\n",
            "Train Epoch: 7 [24400/60000 (41%)]\tLoss: 0.000871\n",
            "Train Epoch: 7 [24800/60000 (41%)]\tLoss: 0.000268\n",
            "Train Epoch: 7 [25200/60000 (42%)]\tLoss: 0.153659\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.004293\n",
            "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.008279\n",
            "Train Epoch: 7 [26400/60000 (44%)]\tLoss: 0.000146\n",
            "Train Epoch: 7 [26800/60000 (45%)]\tLoss: 0.000296\n",
            "Train Epoch: 7 [27200/60000 (45%)]\tLoss: 0.000062\n",
            "Train Epoch: 7 [27600/60000 (46%)]\tLoss: 0.010981\n",
            "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.000100\n",
            "Train Epoch: 7 [28400/60000 (47%)]\tLoss: 0.129102\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.001645\n",
            "Train Epoch: 7 [29200/60000 (49%)]\tLoss: 0.017839\n",
            "Train Epoch: 7 [29600/60000 (49%)]\tLoss: 0.000059\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.000236\n",
            "Train Epoch: 7 [30400/60000 (51%)]\tLoss: 0.000628\n",
            "Train Epoch: 7 [30800/60000 (51%)]\tLoss: 0.039218\n",
            "Train Epoch: 7 [31200/60000 (52%)]\tLoss: 0.000941\n",
            "Train Epoch: 7 [31600/60000 (53%)]\tLoss: 0.000110\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.002129\n",
            "Train Epoch: 7 [32400/60000 (54%)]\tLoss: 0.000552\n",
            "Train Epoch: 7 [32800/60000 (55%)]\tLoss: 0.000134\n",
            "Train Epoch: 7 [33200/60000 (55%)]\tLoss: 0.001354\n",
            "Train Epoch: 7 [33600/60000 (56%)]\tLoss: 0.000058\n",
            "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.000919\n",
            "Train Epoch: 7 [34400/60000 (57%)]\tLoss: 0.694845\n",
            "Train Epoch: 7 [34800/60000 (58%)]\tLoss: 0.000774\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.001115\n",
            "Train Epoch: 7 [35600/60000 (59%)]\tLoss: 0.018893\n",
            "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.004924\n",
            "Train Epoch: 7 [36400/60000 (61%)]\tLoss: 0.000078\n",
            "Train Epoch: 7 [36800/60000 (61%)]\tLoss: 0.000006\n",
            "Train Epoch: 7 [37200/60000 (62%)]\tLoss: 0.004535\n",
            "Train Epoch: 7 [37600/60000 (63%)]\tLoss: 0.005040\n",
            "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.026632\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000083\n",
            "Train Epoch: 7 [38800/60000 (65%)]\tLoss: 0.000039\n",
            "Train Epoch: 7 [39200/60000 (65%)]\tLoss: 0.007312\n",
            "Train Epoch: 7 [39600/60000 (66%)]\tLoss: 0.000210\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.013388\n",
            "Train Epoch: 7 [40400/60000 (67%)]\tLoss: 0.012356\n",
            "Train Epoch: 7 [40800/60000 (68%)]\tLoss: 0.000111\n",
            "Train Epoch: 7 [41200/60000 (69%)]\tLoss: 0.004253\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.066988\n",
            "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.033170\n",
            "Train Epoch: 7 [42400/60000 (71%)]\tLoss: 0.004494\n",
            "Train Epoch: 7 [42800/60000 (71%)]\tLoss: 0.000055\n",
            "Train Epoch: 7 [43200/60000 (72%)]\tLoss: 0.001457\n",
            "Train Epoch: 7 [43600/60000 (73%)]\tLoss: 0.000502\n",
            "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.000019\n",
            "Train Epoch: 7 [44400/60000 (74%)]\tLoss: 0.283462\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000479\n",
            "Train Epoch: 7 [45200/60000 (75%)]\tLoss: 0.001203\n",
            "Train Epoch: 7 [45600/60000 (76%)]\tLoss: 0.006033\n",
            "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.000960\n",
            "Train Epoch: 7 [46400/60000 (77%)]\tLoss: 0.025411\n",
            "Train Epoch: 7 [46800/60000 (78%)]\tLoss: 0.000726\n",
            "Train Epoch: 7 [47200/60000 (79%)]\tLoss: 0.004740\n",
            "Train Epoch: 7 [47600/60000 (79%)]\tLoss: 0.034637\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.000034\n",
            "Train Epoch: 7 [48400/60000 (81%)]\tLoss: 0.003539\n",
            "Train Epoch: 7 [48800/60000 (81%)]\tLoss: 0.003012\n",
            "Train Epoch: 7 [49200/60000 (82%)]\tLoss: 0.007080\n",
            "Train Epoch: 7 [49600/60000 (83%)]\tLoss: 0.013620\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.166123\n",
            "Train Epoch: 7 [50400/60000 (84%)]\tLoss: 0.081074\n",
            "Train Epoch: 7 [50800/60000 (85%)]\tLoss: 0.007120\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000845\n",
            "Train Epoch: 7 [51600/60000 (86%)]\tLoss: 0.212515\n",
            "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.017914\n",
            "Train Epoch: 7 [52400/60000 (87%)]\tLoss: 0.001856\n",
            "Train Epoch: 7 [52800/60000 (88%)]\tLoss: 0.052009\n",
            "Train Epoch: 7 [53200/60000 (89%)]\tLoss: 0.009840\n",
            "Train Epoch: 7 [53600/60000 (89%)]\tLoss: 0.000093\n",
            "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.345862\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.003867\n",
            "Train Epoch: 7 [54800/60000 (91%)]\tLoss: 0.001939\n",
            "Train Epoch: 7 [55200/60000 (92%)]\tLoss: 0.013732\n",
            "Train Epoch: 7 [55600/60000 (93%)]\tLoss: 0.007635\n",
            "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.004175\n",
            "Train Epoch: 7 [56400/60000 (94%)]\tLoss: 0.030613\n",
            "Train Epoch: 7 [56800/60000 (95%)]\tLoss: 0.573678\n",
            "Train Epoch: 7 [57200/60000 (95%)]\tLoss: 0.005180\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.020397\n",
            "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.000072\n",
            "Train Epoch: 7 [58400/60000 (97%)]\tLoss: 0.002628\n",
            "Train Epoch: 7 [58800/60000 (98%)]\tLoss: 0.019574\n",
            "Train Epoch: 7 [59200/60000 (99%)]\tLoss: 0.000120\n",
            "Train Epoch: 7 [59600/60000 (99%)]\tLoss: 0.000417\n",
            "\n",
            "Test set: Average loss: 0.0778, Accuracy: 9813/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.006240\n",
            "Train Epoch: 8 [400/60000 (1%)]\tLoss: 0.121424\n",
            "Train Epoch: 8 [800/60000 (1%)]\tLoss: 0.000747\n",
            "Train Epoch: 8 [1200/60000 (2%)]\tLoss: 0.043728\n",
            "Train Epoch: 8 [1600/60000 (3%)]\tLoss: 0.137256\n",
            "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.008524\n",
            "Train Epoch: 8 [2400/60000 (4%)]\tLoss: 0.000033\n",
            "Train Epoch: 8 [2800/60000 (5%)]\tLoss: 0.000182\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.004198\n",
            "Train Epoch: 8 [3600/60000 (6%)]\tLoss: 0.000690\n",
            "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.008595\n",
            "Train Epoch: 8 [4400/60000 (7%)]\tLoss: 0.000428\n",
            "Train Epoch: 8 [4800/60000 (8%)]\tLoss: 0.000392\n",
            "Train Epoch: 8 [5200/60000 (9%)]\tLoss: 0.066232\n",
            "Train Epoch: 8 [5600/60000 (9%)]\tLoss: 0.000266\n",
            "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.071964\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.096630\n",
            "Train Epoch: 8 [6800/60000 (11%)]\tLoss: 0.000082\n",
            "Train Epoch: 8 [7200/60000 (12%)]\tLoss: 0.005204\n",
            "Train Epoch: 8 [7600/60000 (13%)]\tLoss: 0.000121\n",
            "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.000023\n",
            "Train Epoch: 8 [8400/60000 (14%)]\tLoss: 0.000272\n",
            "Train Epoch: 8 [8800/60000 (15%)]\tLoss: 0.003956\n",
            "Train Epoch: 8 [9200/60000 (15%)]\tLoss: 0.000650\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.152605\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.000039\n",
            "Train Epoch: 8 [10400/60000 (17%)]\tLoss: 0.027642\n",
            "Train Epoch: 8 [10800/60000 (18%)]\tLoss: 0.000028\n",
            "Train Epoch: 8 [11200/60000 (19%)]\tLoss: 0.000064\n",
            "Train Epoch: 8 [11600/60000 (19%)]\tLoss: 0.000006\n",
            "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.000007\n",
            "Train Epoch: 8 [12400/60000 (21%)]\tLoss: 0.000317\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000654\n",
            "Train Epoch: 8 [13200/60000 (22%)]\tLoss: 0.006417\n",
            "Train Epoch: 8 [13600/60000 (23%)]\tLoss: 0.002980\n",
            "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.000373\n",
            "Train Epoch: 8 [14400/60000 (24%)]\tLoss: 0.000026\n",
            "Train Epoch: 8 [14800/60000 (25%)]\tLoss: 0.001451\n",
            "Train Epoch: 8 [15200/60000 (25%)]\tLoss: 0.000006\n",
            "Train Epoch: 8 [15600/60000 (26%)]\tLoss: 0.002372\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.000183\n",
            "Train Epoch: 8 [16400/60000 (27%)]\tLoss: 0.153782\n",
            "Train Epoch: 8 [16800/60000 (28%)]\tLoss: 0.000027\n",
            "Train Epoch: 8 [17200/60000 (29%)]\tLoss: 0.000229\n",
            "Train Epoch: 8 [17600/60000 (29%)]\tLoss: 0.165100\n",
            "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.000074\n",
            "Train Epoch: 8 [18400/60000 (31%)]\tLoss: 0.059583\n",
            "Train Epoch: 8 [18800/60000 (31%)]\tLoss: 0.002652\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.013640\n",
            "Train Epoch: 8 [19600/60000 (33%)]\tLoss: 0.002334\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.000389\n",
            "Train Epoch: 8 [20400/60000 (34%)]\tLoss: 0.000687\n",
            "Train Epoch: 8 [20800/60000 (35%)]\tLoss: 0.024173\n",
            "Train Epoch: 8 [21200/60000 (35%)]\tLoss: 0.012625\n",
            "Train Epoch: 8 [21600/60000 (36%)]\tLoss: 0.001431\n",
            "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.293436\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.011011\n",
            "Train Epoch: 8 [22800/60000 (38%)]\tLoss: 0.001721\n",
            "Train Epoch: 8 [23200/60000 (39%)]\tLoss: 0.081531\n",
            "Train Epoch: 8 [23600/60000 (39%)]\tLoss: 0.000224\n",
            "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.001471\n",
            "Train Epoch: 8 [24400/60000 (41%)]\tLoss: 0.000281\n",
            "Train Epoch: 8 [24800/60000 (41%)]\tLoss: 0.000702\n",
            "Train Epoch: 8 [25200/60000 (42%)]\tLoss: 0.158285\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000314\n",
            "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.006036\n",
            "Train Epoch: 8 [26400/60000 (44%)]\tLoss: 0.001526\n",
            "Train Epoch: 8 [26800/60000 (45%)]\tLoss: 0.000118\n",
            "Train Epoch: 8 [27200/60000 (45%)]\tLoss: 0.010274\n",
            "Train Epoch: 8 [27600/60000 (46%)]\tLoss: 0.000350\n",
            "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.001644\n",
            "Train Epoch: 8 [28400/60000 (47%)]\tLoss: 0.000322\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.001189\n",
            "Train Epoch: 8 [29200/60000 (49%)]\tLoss: 0.001749\n",
            "Train Epoch: 8 [29600/60000 (49%)]\tLoss: 0.002545\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.002353\n",
            "Train Epoch: 8 [30400/60000 (51%)]\tLoss: 0.000060\n",
            "Train Epoch: 8 [30800/60000 (51%)]\tLoss: 0.114705\n",
            "Train Epoch: 8 [31200/60000 (52%)]\tLoss: 0.005350\n",
            "Train Epoch: 8 [31600/60000 (53%)]\tLoss: 0.053130\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.008855\n",
            "Train Epoch: 8 [32400/60000 (54%)]\tLoss: 0.061985\n",
            "Train Epoch: 8 [32800/60000 (55%)]\tLoss: 0.087223\n",
            "Train Epoch: 8 [33200/60000 (55%)]\tLoss: 0.004548\n",
            "Train Epoch: 8 [33600/60000 (56%)]\tLoss: 0.285102\n",
            "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.000460\n",
            "Train Epoch: 8 [34400/60000 (57%)]\tLoss: 0.000636\n",
            "Train Epoch: 8 [34800/60000 (58%)]\tLoss: 0.005865\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.016162\n",
            "Train Epoch: 8 [35600/60000 (59%)]\tLoss: 0.000660\n",
            "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.000196\n",
            "Train Epoch: 8 [36400/60000 (61%)]\tLoss: 0.000104\n",
            "Train Epoch: 8 [36800/60000 (61%)]\tLoss: 0.111287\n",
            "Train Epoch: 8 [37200/60000 (62%)]\tLoss: 0.155514\n",
            "Train Epoch: 8 [37600/60000 (63%)]\tLoss: 0.021072\n",
            "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.150697\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000148\n",
            "Train Epoch: 8 [38800/60000 (65%)]\tLoss: 0.080043\n",
            "Train Epoch: 8 [39200/60000 (65%)]\tLoss: 0.000377\n",
            "Train Epoch: 8 [39600/60000 (66%)]\tLoss: 0.000245\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.021553\n",
            "Train Epoch: 8 [40400/60000 (67%)]\tLoss: 0.002466\n",
            "Train Epoch: 8 [40800/60000 (68%)]\tLoss: 0.000124\n",
            "Train Epoch: 8 [41200/60000 (69%)]\tLoss: 0.017287\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.003255\n",
            "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.000097\n",
            "Train Epoch: 8 [42400/60000 (71%)]\tLoss: 0.228046\n",
            "Train Epoch: 8 [42800/60000 (71%)]\tLoss: 0.000667\n",
            "Train Epoch: 8 [43200/60000 (72%)]\tLoss: 0.000334\n",
            "Train Epoch: 8 [43600/60000 (73%)]\tLoss: 0.000120\n",
            "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.006746\n",
            "Train Epoch: 8 [44400/60000 (74%)]\tLoss: 0.000028\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.010010\n",
            "Train Epoch: 8 [45200/60000 (75%)]\tLoss: 0.000218\n",
            "Train Epoch: 8 [45600/60000 (76%)]\tLoss: 0.003100\n",
            "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.000973\n",
            "Train Epoch: 8 [46400/60000 (77%)]\tLoss: 0.000171\n",
            "Train Epoch: 8 [46800/60000 (78%)]\tLoss: 0.000034\n",
            "Train Epoch: 8 [47200/60000 (79%)]\tLoss: 0.000004\n",
            "Train Epoch: 8 [47600/60000 (79%)]\tLoss: 0.000133\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.024940\n",
            "Train Epoch: 8 [48400/60000 (81%)]\tLoss: 0.068996\n",
            "Train Epoch: 8 [48800/60000 (81%)]\tLoss: 0.001217\n",
            "Train Epoch: 8 [49200/60000 (82%)]\tLoss: 0.000403\n",
            "Train Epoch: 8 [49600/60000 (83%)]\tLoss: 0.000099\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.003668\n",
            "Train Epoch: 8 [50400/60000 (84%)]\tLoss: 0.060764\n",
            "Train Epoch: 8 [50800/60000 (85%)]\tLoss: 0.000672\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000146\n",
            "Train Epoch: 8 [51600/60000 (86%)]\tLoss: 0.000017\n",
            "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.006499\n",
            "Train Epoch: 8 [52400/60000 (87%)]\tLoss: 0.001633\n",
            "Train Epoch: 8 [52800/60000 (88%)]\tLoss: 0.008668\n",
            "Train Epoch: 8 [53200/60000 (89%)]\tLoss: 0.000146\n",
            "Train Epoch: 8 [53600/60000 (89%)]\tLoss: 0.000008\n",
            "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.000011\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.000493\n",
            "Train Epoch: 8 [54800/60000 (91%)]\tLoss: 0.000208\n",
            "Train Epoch: 8 [55200/60000 (92%)]\tLoss: 0.030670\n",
            "Train Epoch: 8 [55600/60000 (93%)]\tLoss: 0.002797\n",
            "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.000201\n",
            "Train Epoch: 8 [56400/60000 (94%)]\tLoss: 0.004010\n",
            "Train Epoch: 8 [56800/60000 (95%)]\tLoss: 0.002569\n",
            "Train Epoch: 8 [57200/60000 (95%)]\tLoss: 0.588660\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.005987\n",
            "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.303682\n",
            "Train Epoch: 8 [58400/60000 (97%)]\tLoss: 0.000068\n",
            "Train Epoch: 8 [58800/60000 (98%)]\tLoss: 0.000834\n",
            "Train Epoch: 8 [59200/60000 (99%)]\tLoss: 0.007505\n",
            "Train Epoch: 8 [59600/60000 (99%)]\tLoss: 0.000009\n",
            "\n",
            "Test set: Average loss: 0.0692, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.049650\n",
            "Train Epoch: 9 [400/60000 (1%)]\tLoss: 0.001027\n",
            "Train Epoch: 9 [800/60000 (1%)]\tLoss: 0.000048\n",
            "Train Epoch: 9 [1200/60000 (2%)]\tLoss: 0.001152\n",
            "Train Epoch: 9 [1600/60000 (3%)]\tLoss: 0.000714\n",
            "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.000968\n",
            "Train Epoch: 9 [2400/60000 (4%)]\tLoss: 0.001772\n",
            "Train Epoch: 9 [2800/60000 (5%)]\tLoss: 0.000893\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.001794\n",
            "Train Epoch: 9 [3600/60000 (6%)]\tLoss: 0.000015\n",
            "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.000564\n",
            "Train Epoch: 9 [4400/60000 (7%)]\tLoss: 0.000015\n",
            "Train Epoch: 9 [4800/60000 (8%)]\tLoss: 0.001666\n",
            "Train Epoch: 9 [5200/60000 (9%)]\tLoss: 0.001475\n",
            "Train Epoch: 9 [5600/60000 (9%)]\tLoss: 0.000285\n",
            "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.000092\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000806\n",
            "Train Epoch: 9 [6800/60000 (11%)]\tLoss: 0.005921\n",
            "Train Epoch: 9 [7200/60000 (12%)]\tLoss: 0.000460\n",
            "Train Epoch: 9 [7600/60000 (13%)]\tLoss: 0.001333\n",
            "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.505954\n",
            "Train Epoch: 9 [8400/60000 (14%)]\tLoss: 0.004566\n",
            "Train Epoch: 9 [8800/60000 (15%)]\tLoss: 0.115453\n",
            "Train Epoch: 9 [9200/60000 (15%)]\tLoss: 0.000030\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.014712\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.083992\n",
            "Train Epoch: 9 [10400/60000 (17%)]\tLoss: 0.000825\n",
            "Train Epoch: 9 [10800/60000 (18%)]\tLoss: 0.000026\n",
            "Train Epoch: 9 [11200/60000 (19%)]\tLoss: 0.002516\n",
            "Train Epoch: 9 [11600/60000 (19%)]\tLoss: 0.001110\n",
            "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.000100\n",
            "Train Epoch: 9 [12400/60000 (21%)]\tLoss: 0.011726\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.005455\n",
            "Train Epoch: 9 [13200/60000 (22%)]\tLoss: 0.006959\n",
            "Train Epoch: 9 [13600/60000 (23%)]\tLoss: 0.005018\n",
            "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.000139\n",
            "Train Epoch: 9 [14400/60000 (24%)]\tLoss: 0.000396\n",
            "Train Epoch: 9 [14800/60000 (25%)]\tLoss: 0.030514\n",
            "Train Epoch: 9 [15200/60000 (25%)]\tLoss: 0.000023\n",
            "Train Epoch: 9 [15600/60000 (26%)]\tLoss: 0.002302\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.000327\n",
            "Train Epoch: 9 [16400/60000 (27%)]\tLoss: 0.127353\n",
            "Train Epoch: 9 [16800/60000 (28%)]\tLoss: 0.001018\n",
            "Train Epoch: 9 [17200/60000 (29%)]\tLoss: 0.000021\n",
            "Train Epoch: 9 [17600/60000 (29%)]\tLoss: 0.000247\n",
            "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.046849\n",
            "Train Epoch: 9 [18400/60000 (31%)]\tLoss: 0.000081\n",
            "Train Epoch: 9 [18800/60000 (31%)]\tLoss: 0.000525\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000021\n",
            "Train Epoch: 9 [19600/60000 (33%)]\tLoss: 0.001244\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.000343\n",
            "Train Epoch: 9 [20400/60000 (34%)]\tLoss: 0.001375\n",
            "Train Epoch: 9 [20800/60000 (35%)]\tLoss: 0.000054\n",
            "Train Epoch: 9 [21200/60000 (35%)]\tLoss: 0.001681\n",
            "Train Epoch: 9 [21600/60000 (36%)]\tLoss: 0.000500\n",
            "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.006186\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.000010\n",
            "Train Epoch: 9 [22800/60000 (38%)]\tLoss: 0.001293\n",
            "Train Epoch: 9 [23200/60000 (39%)]\tLoss: 0.000078\n",
            "Train Epoch: 9 [23600/60000 (39%)]\tLoss: 0.000627\n",
            "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.000452\n",
            "Train Epoch: 9 [24400/60000 (41%)]\tLoss: 0.422997\n",
            "Train Epoch: 9 [24800/60000 (41%)]\tLoss: 0.000215\n",
            "Train Epoch: 9 [25200/60000 (42%)]\tLoss: 0.000041\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.059046\n",
            "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.000262\n",
            "Train Epoch: 9 [26400/60000 (44%)]\tLoss: 0.001982\n",
            "Train Epoch: 9 [26800/60000 (45%)]\tLoss: 0.000190\n",
            "Train Epoch: 9 [27200/60000 (45%)]\tLoss: 0.000867\n",
            "Train Epoch: 9 [27600/60000 (46%)]\tLoss: 0.000112\n",
            "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.000111\n",
            "Train Epoch: 9 [28400/60000 (47%)]\tLoss: 0.036859\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.041270\n",
            "Train Epoch: 9 [29200/60000 (49%)]\tLoss: 0.001772\n",
            "Train Epoch: 9 [29600/60000 (49%)]\tLoss: 0.001138\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.176702\n",
            "Train Epoch: 9 [30400/60000 (51%)]\tLoss: 0.000520\n",
            "Train Epoch: 9 [30800/60000 (51%)]\tLoss: 0.000907\n",
            "Train Epoch: 9 [31200/60000 (52%)]\tLoss: 0.009796\n",
            "Train Epoch: 9 [31600/60000 (53%)]\tLoss: 0.000396\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000596\n",
            "Train Epoch: 9 [32400/60000 (54%)]\tLoss: 0.000895\n",
            "Train Epoch: 9 [32800/60000 (55%)]\tLoss: 0.000377\n",
            "Train Epoch: 9 [33200/60000 (55%)]\tLoss: 0.002710\n",
            "Train Epoch: 9 [33600/60000 (56%)]\tLoss: 0.000019\n",
            "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.000081\n",
            "Train Epoch: 9 [34400/60000 (57%)]\tLoss: 0.000020\n",
            "Train Epoch: 9 [34800/60000 (58%)]\tLoss: 0.000027\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.000231\n",
            "Train Epoch: 9 [35600/60000 (59%)]\tLoss: 0.072398\n",
            "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.000553\n",
            "Train Epoch: 9 [36400/60000 (61%)]\tLoss: 0.017064\n",
            "Train Epoch: 9 [36800/60000 (61%)]\tLoss: 0.000006\n",
            "Train Epoch: 9 [37200/60000 (62%)]\tLoss: 0.004896\n",
            "Train Epoch: 9 [37600/60000 (63%)]\tLoss: 0.015774\n",
            "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.000347\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000800\n",
            "Train Epoch: 9 [38800/60000 (65%)]\tLoss: 0.594479\n",
            "Train Epoch: 9 [39200/60000 (65%)]\tLoss: 0.000981\n",
            "Train Epoch: 9 [39600/60000 (66%)]\tLoss: 0.005276\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.015335\n",
            "Train Epoch: 9 [40400/60000 (67%)]\tLoss: 0.006639\n",
            "Train Epoch: 9 [40800/60000 (68%)]\tLoss: 0.027316\n",
            "Train Epoch: 9 [41200/60000 (69%)]\tLoss: 0.017428\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.000167\n",
            "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.050342\n",
            "Train Epoch: 9 [42400/60000 (71%)]\tLoss: 0.107574\n",
            "Train Epoch: 9 [42800/60000 (71%)]\tLoss: 0.008199\n",
            "Train Epoch: 9 [43200/60000 (72%)]\tLoss: 0.000217\n",
            "Train Epoch: 9 [43600/60000 (73%)]\tLoss: 0.000122\n",
            "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.002086\n",
            "Train Epoch: 9 [44400/60000 (74%)]\tLoss: 0.000694\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.025567\n",
            "Train Epoch: 9 [45200/60000 (75%)]\tLoss: 0.001805\n",
            "Train Epoch: 9 [45600/60000 (76%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.000076\n",
            "Train Epoch: 9 [46400/60000 (77%)]\tLoss: 0.000119\n",
            "Train Epoch: 9 [46800/60000 (78%)]\tLoss: 0.000645\n",
            "Train Epoch: 9 [47200/60000 (79%)]\tLoss: 0.013526\n",
            "Train Epoch: 9 [47600/60000 (79%)]\tLoss: 0.052689\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.000001\n",
            "Train Epoch: 9 [48400/60000 (81%)]\tLoss: 0.000015\n",
            "Train Epoch: 9 [48800/60000 (81%)]\tLoss: 0.038591\n",
            "Train Epoch: 9 [49200/60000 (82%)]\tLoss: 0.001130\n",
            "Train Epoch: 9 [49600/60000 (83%)]\tLoss: 0.034553\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.000890\n",
            "Train Epoch: 9 [50400/60000 (84%)]\tLoss: 0.025340\n",
            "Train Epoch: 9 [50800/60000 (85%)]\tLoss: 0.010150\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000708\n",
            "Train Epoch: 9 [51600/60000 (86%)]\tLoss: 0.000134\n",
            "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.000696\n",
            "Train Epoch: 9 [52400/60000 (87%)]\tLoss: 0.000001\n",
            "Train Epoch: 9 [52800/60000 (88%)]\tLoss: 0.000295\n",
            "Train Epoch: 9 [53200/60000 (89%)]\tLoss: 0.072009\n",
            "Train Epoch: 9 [53600/60000 (89%)]\tLoss: 0.000023\n",
            "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.004836\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.001256\n",
            "Train Epoch: 9 [54800/60000 (91%)]\tLoss: 0.000004\n",
            "Train Epoch: 9 [55200/60000 (92%)]\tLoss: 0.001551\n",
            "Train Epoch: 9 [55600/60000 (93%)]\tLoss: 0.000009\n",
            "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.000854\n",
            "Train Epoch: 9 [56400/60000 (94%)]\tLoss: 0.000146\n",
            "Train Epoch: 9 [56800/60000 (95%)]\tLoss: 0.000172\n",
            "Train Epoch: 9 [57200/60000 (95%)]\tLoss: 0.000002\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000015\n",
            "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.000400\n",
            "Train Epoch: 9 [58400/60000 (97%)]\tLoss: 0.004407\n",
            "Train Epoch: 9 [58800/60000 (98%)]\tLoss: 0.000339\n",
            "Train Epoch: 9 [59200/60000 (99%)]\tLoss: 0.115934\n",
            "Train Epoch: 9 [59600/60000 (99%)]\tLoss: 0.004111\n",
            "\n",
            "Test set: Average loss: 0.0854, Accuracy: 9815/10000 (98%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.000027\n",
            "Train Epoch: 10 [400/60000 (1%)]\tLoss: 0.022111\n",
            "Train Epoch: 10 [800/60000 (1%)]\tLoss: 0.000404\n",
            "Train Epoch: 10 [1200/60000 (2%)]\tLoss: 0.284623\n",
            "Train Epoch: 10 [1600/60000 (3%)]\tLoss: 0.007766\n",
            "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.000513\n",
            "Train Epoch: 10 [2400/60000 (4%)]\tLoss: 0.000557\n",
            "Train Epoch: 10 [2800/60000 (5%)]\tLoss: 0.007169\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.000125\n",
            "Train Epoch: 10 [3600/60000 (6%)]\tLoss: 0.000002\n",
            "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.079047\n",
            "Train Epoch: 10 [4400/60000 (7%)]\tLoss: 0.235231\n",
            "Train Epoch: 10 [4800/60000 (8%)]\tLoss: 0.000120\n",
            "Train Epoch: 10 [5200/60000 (9%)]\tLoss: 0.000028\n",
            "Train Epoch: 10 [5600/60000 (9%)]\tLoss: 0.006635\n",
            "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.203530\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.000089\n",
            "Train Epoch: 10 [6800/60000 (11%)]\tLoss: 0.000835\n",
            "Train Epoch: 10 [7200/60000 (12%)]\tLoss: 0.000321\n",
            "Train Epoch: 10 [7600/60000 (13%)]\tLoss: 0.000313\n",
            "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.000031\n",
            "Train Epoch: 10 [8400/60000 (14%)]\tLoss: 0.289878\n",
            "Train Epoch: 10 [8800/60000 (15%)]\tLoss: 0.000135\n",
            "Train Epoch: 10 [9200/60000 (15%)]\tLoss: 0.000668\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.001095\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.000022\n",
            "Train Epoch: 10 [10400/60000 (17%)]\tLoss: 0.001313\n",
            "Train Epoch: 10 [10800/60000 (18%)]\tLoss: 0.000011\n",
            "Train Epoch: 10 [11200/60000 (19%)]\tLoss: 0.020824\n",
            "Train Epoch: 10 [11600/60000 (19%)]\tLoss: 0.000058\n",
            "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.000020\n",
            "Train Epoch: 10 [12400/60000 (21%)]\tLoss: 0.000543\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.056506\n",
            "Train Epoch: 10 [13200/60000 (22%)]\tLoss: 0.001031\n",
            "Train Epoch: 10 [13600/60000 (23%)]\tLoss: 0.016371\n",
            "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.034203\n",
            "Train Epoch: 10 [14400/60000 (24%)]\tLoss: 0.019267\n",
            "Train Epoch: 10 [14800/60000 (25%)]\tLoss: 0.000237\n",
            "Train Epoch: 10 [15200/60000 (25%)]\tLoss: 0.010908\n",
            "Train Epoch: 10 [15600/60000 (26%)]\tLoss: 0.000150\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.004761\n",
            "Train Epoch: 10 [16400/60000 (27%)]\tLoss: 0.033743\n",
            "Train Epoch: 10 [16800/60000 (28%)]\tLoss: 0.000023\n",
            "Train Epoch: 10 [17200/60000 (29%)]\tLoss: 0.000165\n",
            "Train Epoch: 10 [17600/60000 (29%)]\tLoss: 0.000227\n",
            "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.000407\n",
            "Train Epoch: 10 [18400/60000 (31%)]\tLoss: 0.001520\n",
            "Train Epoch: 10 [18800/60000 (31%)]\tLoss: 0.000210\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.000029\n",
            "Train Epoch: 10 [19600/60000 (33%)]\tLoss: 0.000186\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.000903\n",
            "Train Epoch: 10 [20400/60000 (34%)]\tLoss: 0.001108\n",
            "Train Epoch: 10 [20800/60000 (35%)]\tLoss: 0.142482\n",
            "Train Epoch: 10 [21200/60000 (35%)]\tLoss: 0.000690\n",
            "Train Epoch: 10 [21600/60000 (36%)]\tLoss: 0.018631\n",
            "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.074668\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.000173\n",
            "Train Epoch: 10 [22800/60000 (38%)]\tLoss: 0.000270\n",
            "Train Epoch: 10 [23200/60000 (39%)]\tLoss: 0.014561\n",
            "Train Epoch: 10 [23600/60000 (39%)]\tLoss: 0.001747\n",
            "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.000007\n",
            "Train Epoch: 10 [24400/60000 (41%)]\tLoss: 0.000007\n",
            "Train Epoch: 10 [24800/60000 (41%)]\tLoss: 0.002593\n",
            "Train Epoch: 10 [25200/60000 (42%)]\tLoss: 0.000019\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.011826\n",
            "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.005212\n",
            "Train Epoch: 10 [26400/60000 (44%)]\tLoss: 0.011415\n",
            "Train Epoch: 10 [26800/60000 (45%)]\tLoss: 0.023779\n",
            "Train Epoch: 10 [27200/60000 (45%)]\tLoss: 0.005410\n",
            "Train Epoch: 10 [27600/60000 (46%)]\tLoss: 0.000295\n",
            "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.004078\n",
            "Train Epoch: 10 [28400/60000 (47%)]\tLoss: 0.119506\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.000005\n",
            "Train Epoch: 10 [29200/60000 (49%)]\tLoss: 0.056936\n",
            "Train Epoch: 10 [29600/60000 (49%)]\tLoss: 0.000164\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.000035\n",
            "Train Epoch: 10 [30400/60000 (51%)]\tLoss: 0.004610\n",
            "Train Epoch: 10 [30800/60000 (51%)]\tLoss: 0.000005\n",
            "Train Epoch: 10 [31200/60000 (52%)]\tLoss: 0.001030\n",
            "Train Epoch: 10 [31600/60000 (53%)]\tLoss: 0.000132\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.000022\n",
            "Train Epoch: 10 [32400/60000 (54%)]\tLoss: 0.167056\n",
            "Train Epoch: 10 [32800/60000 (55%)]\tLoss: 0.000014\n",
            "Train Epoch: 10 [33200/60000 (55%)]\tLoss: 0.001695\n",
            "Train Epoch: 10 [33600/60000 (56%)]\tLoss: 0.028437\n",
            "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.000042\n",
            "Train Epoch: 10 [34400/60000 (57%)]\tLoss: 0.000032\n",
            "Train Epoch: 10 [34800/60000 (58%)]\tLoss: 0.000673\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.032188\n",
            "Train Epoch: 10 [35600/60000 (59%)]\tLoss: 0.000741\n",
            "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.000070\n",
            "Train Epoch: 10 [36400/60000 (61%)]\tLoss: 0.000378\n",
            "Train Epoch: 10 [36800/60000 (61%)]\tLoss: 0.077935\n",
            "Train Epoch: 10 [37200/60000 (62%)]\tLoss: 0.001188\n",
            "Train Epoch: 10 [37600/60000 (63%)]\tLoss: 0.010621\n",
            "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.000067\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002687\n",
            "Train Epoch: 10 [38800/60000 (65%)]\tLoss: 0.185041\n",
            "Train Epoch: 10 [39200/60000 (65%)]\tLoss: 0.000024\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0ae82b57b1c8>\u001b[0m in \u001b[0;36m<cell line: 202>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Run the training and testing for defined epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-0ae82b57b1c8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Put model in training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Move data and targets to device (GPU/CPU)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    920\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import torch.cuda as torch_cuda\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "print('===VERIFY GPU===')\n",
        "print('CUDA IS AVAILABLE:', torch_cuda.is_available())\n",
        "print('DEVICE COUNT:', torch_cuda.device_count())\n",
        "print('DEVICE NAME:', torch_cuda.get_device_name(0))\n",
        "\n",
        "# If CUDA is available, print GPU details\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0)} bytes\")\n",
        "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0)} bytes\")\n",
        "\n",
        "# Select device: GPU if available, otherwise CPU\n",
        "device = torch.device('cuda:0' if torch_cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "momentum_coeff = 0.9\n",
        "learning_rate = 0.01\n",
        "learning_decay = 10**-9\n",
        "epochs = 100\n",
        "\n",
        "# Classes for MNIST digits\n",
        "classes = (0,1,2,3,4,5,6,7,8,9)\n",
        "\n",
        "# Define a multi-layer perceptron (MLP) model\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        # Flatten layer to convert 28x28 images into 784-dim vector\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        # Define linear layers\n",
        "        self.input_layer = nn.Linear(784, 1000)\n",
        "        self.hidden_layer1 = nn.Linear(1000, 1000)\n",
        "        self.hidden_layer2 = nn.Linear(1000, 1000)\n",
        "        self.hidden_layer3 = nn.Linear(1000, 1000)\n",
        "        self.hidden_layer4 = nn.Linear(1000, 1000)\n",
        "        self.out = nn.Linear(1000, 10)\n",
        "\n",
        "        # Define dropout layers\n",
        "        self.dropout_layer1 = nn.Dropout(p=0.2)\n",
        "        self.dropout_layer2 = nn.Dropout(p=0.3)\n",
        "        self.dropout_layer3 = nn.Dropout(p=0.4)\n",
        "        self.dropout_layer4 = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the image into a 784-dim vector\n",
        "        x = x.reshape(-1, 784)\n",
        "\n",
        "        # Pass through layers with ReLU activation and dropout\n",
        "        x = F.relu(self.input_layer(x))\n",
        "        x = self.dropout_layer1(F.relu(self.hidden_layer1(x)))\n",
        "        x = self.dropout_layer2(F.relu(self.hidden_layer2(x)))\n",
        "        x = self.dropout_layer3(F.relu(self.hidden_layer3(x)))\n",
        "        x = self.dropout_layer4(F.relu(self.hidden_layer4(x)))\n",
        "\n",
        "        # IMPORTANT FIX: Do not apply softmax here.\n",
        "        # CrossEntropyLoss expects raw logits.\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x  # Return raw logits\n",
        "\n",
        "# Instantiate and move model to the selected device\n",
        "mlp = MLP().to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()  # CrossEntropyLoss expects raw logits\n",
        "optimizer = optim.SGD(mlp.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum_coeff, weight_decay=learning_decay)\n",
        "\n",
        "# Define transformations: Convert to tensor and normalize\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "\n",
        "mnist_trainset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transformations\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(\n",
        "    mnist_trainset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "mnist_testset = datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transformations\n",
        ")\n",
        "\n",
        "\n",
        "testloader = DataLoader(\n",
        "    mnist_testset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "print('TRAIN SET LENGTH:', len(mnist_trainset))\n",
        "print('TEST SET LENGTH:', len(mnist_testset))\n",
        "\n",
        "def imshow(img):\n",
        "\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imshow(make_grid(images))\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "    mlp.train()\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = mlp(data)\n",
        "\n",
        "\n",
        "        loss = loss_function(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 25 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
        "                100. * batch_idx / len(trainloader), loss.item()))\n",
        "\n",
        "\n",
        "def test():\n",
        "    mlp.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in testloader:\n",
        "            # Move data and targets to device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            output = mlp(data)\n",
        "\n",
        "            # Compute loss and accumulate\n",
        "            test_loss += loss_function(output, target).item()\n",
        "\n",
        "            # Get predicted classes\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            # Count how many predictions are correct\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    # Average loss over the entire test set\n",
        "    test_loss /= len(testloader)\n",
        "\n",
        "    # Print test performance\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))\n",
        "\n",
        "\n",
        "# Run the training and testing for defined epochs\n",
        "for epoch in range(epochs):\n",
        "    train(epoch)\n",
        "    test()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUiN5wnOjql-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}